# 3D-modelling
**My 3D modelling projects and progress**  
Hello. I’m Arjun Khara, a student at Goldsmiths College, University of London. This is my introduction to Maya and 3D modelling. As this is my first time using 3D modelling software, I will be documenting all my learnings with Maya for the purposes of the module, as well as to provide a rudimentary introduction to future students of this module who, like me, have no experience with 3D software but are eager to learn as much and as quickly as possible.

___

<h2>LINKS TO GAMES PROGRAMMING + 3D-MODELLING REPOSITORIES</h2>

<h3>PROGRAMMING REPOSITORY</h3>
<strong>• Complete Programming Repository:</strong><br/> 
https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo<br/>

<strong>• Programming Repository Readme File, containing my Final Report:</strong><br/> 
https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints.md<br/>


<h3>3D-MODELLING REPOSITORY</h3>
<strong>• Complete 3D Modelling Repository:</strong><br/> 
https://github.com/arjunkhara/3D-Modelling-Repo<br/>

<strong>• 3D Modelling Repository Readme File, containing my Final Report (end of this document):</strong><br/> 
https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/README.md<br/>


<h3>GITHUB REPOSITORIES HOMEPAGE</h3>
<strong>• GitHub Repositories Homepage:</strong><br/> 
https://github.com/arjunkhara<br/>


<h3>YOUTUBE GAME DEMO & PLAY-THROUGH</h3>
<strong>• Game demo and quick play-through on YouTube:</strong><br/> 
https://youtu.be/9MxDqQASxD8

___


![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide1.PNG "Basic 3D Modelling Setup from Zero Knowledge")

<h1>Week 1: Maya, Familiarisation, and Simple Shapes</h1>

In this introduction to Maya (lesson 1 of Introduction to Modelling) I have added a doughnut and a cylinder to the scene. Using the vertex and face tools (from the right-click popup menu) I have created a mildly complex shape. In this scene I have managed to elongate the doughnut by using the extrude tool. So far this is purely experimental and playing with the tools is important, especially in a completely unfamiliar environment with such a wide plethora of tools, windows, panels, and dropdowns.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide2.PNG "Tooling Basics")

Just by switching between the tools (Q for select, W for move, E for rotate, and R for scale) and by pulling, pushing and pinching the faces, vertices, edges, and vertex points, a variety of interesting shapes can be created. Here I am trying to draw a space age piston. It’s not a very good job but this is the first time in my life that I have ever used 3D modelling software. The choice is between Maya and Blender and I have chosen Maya.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide3.PNG "Faces, Vertices, Edges, and Planes")

Here is the completed piston for the engine. When selecting anything in Object Mode (right mouse button over any asset will bring up the options) the asset and its wireframe components light up in a light green colour as shown in the image.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide4.PNG "Wireframing Components")

Here I have simply placed a cube onto the scene next to my piston. I figured if the only component I have is a piston then the rest of the spaceship engine is missing, in which case there must have been a crash. This method of assigning myself a story works well in creating abstract shapes since a narrative almost always puts a definite object in mind. This, I find, is the best way to approach any creative software or factured process.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide5.PNG "Adding Narratives to Scene")

In this scene I have simply pushed and pulled on vertex points and faces of the cube to create a sort of crushed and damaged look. I have also figured out how to apply a bevel effect to individual faces of the cube, which can be found under the Edit Mesh dropdown menu option. Together with Extrude (also under Edit Mesh) a variety of interesting shapes can be produced.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide6.PNG "Beveling and Extruding")

Here I have highlighted the vertex points by right clicking the cube and selecting Vertex from the popup menu. I am told this popup menu will be the backbone for the tools of Maya and so I am trying to get used to the presence of this menu as well as the process for calling it up – right click any object to bring up the popup menu.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide7.PNG "Manipulating Vertices")

In this scene I have made a deep extrusion on one side of the cube’s face. This is done by selecting an object, in this case the cube, right clicking and choosing Faces, and then extruding the face inside the cube. I then placed the piston next to the damaged piece so that the narrative speaks for itself – in this case the piston head might have fitted in the round hole in the cube at an earlier point before the crash.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide8.PNG "Creating Realistic Shapes")

More experimentation with shapes, this time with a sphere. I simply generated the sphere then applied several divisions to it by choosing Edit Mesh > Add Divisions. It is possible to drag the sphere right onto the new cube and make them appear as one. The idea is to get a feel for the pseudo 3D space in which all the assets and objects operate within. I asked about how to move objects to the back / front of each other – as is the case in Illustrator or Photoshop, but in Maya we are working in 3D space, in which case multidimensional spatial thinking is required. I believe Maya also has layers though.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide9.PNG "Adding Divisions")

I have just discovered the orthographical view, which shows the plane of perspective from four set points as shown in the image above. This is extremely handy for positioning objects and general perception since the 3D default view is not always perceived accurately. Access this view by simply hitting the space bar. When in this view, click on any of the planes of perspective and hit space bar to make that plane the default view. I suspect I will be toggling between these planes regularly. Note the importance of Maya's co-ordinate systems for manipulating objects: global (default option), local (object-oriented) and independent or arbitrary (based on user's manipulation point). Depending on what co-ordinate system is being used, the object will be manipulated accordingly. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide10.PNG "Orthographic Views")

More refinements have been done to the cube and sphere. I am trying to build a meteorite that conveys some sense of cause and effect for the crash scene. In this scene the meteorite that hit the ship’s engines landed close to the crash site.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide11.PNG "Refinements to Details")

Fortunately, the crash was next to a spare parts yard. I learned how to duplicate assets. The process is straightforward. Select an asset and make sure the mode is set to Objects. (Right Mouse Button). Then hit CTRL + D and the object is cloned. Note that the cloned object sits exactly where the original object is and so it may appear that nothing has transpired. As soon as cloning is completed, switch to the move tool (W) and move the cloned object to an empty space. Otherwise if the cloned object contains more than one asset (e.g. the sphere and cube in the previous image) it is almost impossible to select just the multiple cloned objects.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide12.PNG "Duplicating and Cloning")

Getting familiar with the UI for faster workflow – a small but crucial step. By clicking on any of the dropdown menu options and clicking the thin double-row dots item at the very top of the dropdown menu, you can undock the menu from the window and position it anywhere on the canvas. This is extremely handy when using a menu option like Modify, Mesh, or Edit Mesh for extended periods. To get rid of these floating menus, simply click the red X at the top of the menu. Note: the floating menus do not affect the top window menu, which remains in place regardless.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide13.PNG "Undocking Panels and Speeding Up Workflows")

Rotating around a default pivot point will not always work. Sometimes you will want to change the pivot point. You can achieve this by switching to ‘Front View’ and using shortcut F to focus, and then pressing D to bring up the pivot point crosshairs. This option allows you to move the default pivot point around which a polygon rotates, to any point of your choosing where you would like the rotation to occur. Here you can see the pivot point has been changed by dragging it down to the base of the cone. You can see from the image how the point has been moved to bottom of the polygon. The Modify menu has plenty of useful feature. One particularly useful option is Center Pivot. Use Center Pivot to return the pivot point to the default position. Alternatively, you can also use Reset Transformations but note that clicking on this option will result in your entire polygon changes being restored to default, including its position, scale, and rotation.
![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide14.png  "Rotation and Default Pivot Points")

Freeze transformations resets the objects edit properties to zero with reference to the new origin. This is useful to prevent any accidental shifts or changes to the object, especially after fine-tuning its position in the Attribute Editor pane (right-hand side of the screen). ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide15.png "Zero Reference Objects")

When using the free transformations tool, you can further choose which edit options you would like effected – for example if you only want to edit the Translate properties but not Rotate and Scale, uncheck all the other options and keep only the Translate option checked. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide16.png "Free Transformation Tools")

If for any reason you want to return to the default options of this toolbox, simply click on Edit, then Reset Settings to re-establish the default settings that Maya configures / recommends. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide17.png "Resetting to Original Settings")

The Outliner view will quickly become a reliable friend. Apart from providing two-pane custom views of your objects, which allow you to see your assets in limited 2D and 3D perspective, the Outliner also lets you choose and rename your assets by clicking on the item in the list. This is especially useful when working on large projects where organisation and identification of assets (especially across teams) is critical for success. Here is the image reference: ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide18.png "Outliner View and Assets Management")

The Mesh tool is critical for merging, separating and reconstructing assets. In this example I have a cube. By selecting the Face option from the Right-Click Mouse Button, I can select any of the faces of the cube and delete them. To bring the deleted face back, select the Edge option from the Right-Click Mouse Button, then hold down Shift and select all four edges of the empty face, or simply double-click one edge to select all four edges of that empty face. Go to Mesh, and click Fill Hole. The cube is reconstructed. The Mesh pane describes all the options under each of its sub-section headings. Fill Hole is under the Remesh sub-section heading. Here is the image reference: ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide19.PNG "Merging and Mesh Plane Edits")

<h1>Week 2: Week 1 + Complex Shapes and Morphs]</h1>

By selecting any polygon and hitting 3 on the number pad, Maya applies a smoothening effect to the polygon while maintaining the number of polygons. This is very handy to keep polygon counts low, especially for highly limited resource gaming projects. Pressing 1 on the number pad will return your polygon to its original shape. Pressing 2 on the number pad will create the same effect as pressing 3, but will retain an outline of the original polygon shape. However, note that the Mesh panel also has a smoothening option which is similar with the difference being that Mesh smoothening results in more geometry to the polygon and creates a new topology to the shape. The smoothening effect can be applied repeatedly, which will increase the polygon’s geometry by continuing to change its geometry. Here is the image reference: ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide20.png "Polygon Smootheneing Effect")

From a regular cube to a protruding diamond. The Edit Mesh property has plenty of amendment options to regular polygons. In this example I have used the Bevel option from the Edit Mesh panel and changed the Fraction value (in the resulting pop-up) from the default 0.5 to 1. The Bevel option adds additional divisions to the polygon. Adjusting the Fraction value will increase / decrease the depth of the polygon. Adjusting the Segments value will add / remove the number of segments to the polygon. Toggling Chamfer on / off results in rounded corners to your polygon (off means straight corners, on means rounded corners). This pop-up box will be extremely handy for modelling complex shapes. To get rid of the pop-up select any polygon and hit W, E, or R. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide21.png "Chamfer and Mesh Properties")

The image of the cube above was created in response to week 2’s challenge to explore vertices in creating smooth edges and curves for polygons without compromising polygon count. The week’s chapter explored vertices, faces, and edges and explained the importance of each in relation to the other factors that determine smooth object rendering in game engines without overloading resources. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide22.png "High Smootheneing with Low Poly Count")

I tried to go beyond week 2’s requirements to create a narrative of my own development with Maya and modelling. This here is a symbol of strength and training – a reminder of the need to consistently practice with the software and keep up-to-date with the methods and best practices. The result is a dumbbell, created with two cubes that I combined using the Mesh panel. I then deleted the face of both cubes that were pointing towards each other. With the four edges of both missing faces on either cube selected, I created a bridge between the two from the Edit Mesh panel, and played with the Fraction, Twist and Segment values till I got the shape I wanted. Then I smoothened the entire structure to create this shape. Note that with bridges, the number of edges selected should ideally be the same for a smooth transition. Selecting disproportional edges to bridge across assets will typically result in skewed or funky shapes, usually characterised by additional triangles, that require manual clean up. To preserve smooth workflow, ensure that the number of edges remain equal on both sides of the bridge. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide23.png "Complex Dumbell From Simple Cube")

Still just experimenting with the tools learned so far, I decided to create a simple concept of a variable dumbbell weight which can be filled with sand or water (materials I would like to explore later and which are essential to level design) I toggled to the Faces option from the Right Mouse Button, and selected the two faces you see here hovering above the dumbbell. Then from Edit Mesh I selected the Detach option and simply lifted the two faces off the rest of the polygon, by switching to the move option, W. The dumbbell now has a deeper narrative owing to the juxtaposition of weight and strength versus hollowness and intrigue. By manipulating a few faces, edges, vertices, and options from the Edit Mesh panel, Maya can provide a lot of inspiration for narratives, story concepts, and maybe ultimately even a fresh idea for the next game. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide24.png "Detached Faces")

The Extrude option under Edit Mesh will be a vital tool for modelling interesting and whacky objects. Here I have used the Extrude tool (in precisely the same order as the Detach tool from the example prior to this) to give extra body and dimensions to the dumbbell and the raised faces. The voluminous look creates some added appeal – perhaps the building blocks for a spaceship scene. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide25.png "Extruding Faces in Complex Shapes")

Using a combination of tools from the Edit Mesh panel I created a warp engine concept with an extendable recharging boom and a damaged transducer. The complexity of shapes is manageable using the History pane. Further refinements are possible as the toolsets for Maya become more familiar. Again, keep experimenting with the polygons and their controls. A good tip is to keep building off from the beginning then launching one step further. For example start with step 1. Then do step 1 and step 2. Then repeat step 1 and step 2 and add step 3. Then repeat steps 1, 2, and 3 and add step 4. This layered style learning loops your hands-on experience and reinforces memory of previously learned concepts and controls. Also, always balance concepts with control. Don’t let either the tools or the ideas get ahead of each other. Keeping them both in check will result in a smoother project flow. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide26.png "Extruding Faces in Complex Shapes")

And so the repertoire of assets, objects and creativity grows. At this stage I have tried to challenge myself to begin creating assets that emulate a bit more of real life rather than let my imagination reign without guides. Giving myself a concrete example or object to create, in this case pistons and serrated ball bearings, provided greater guidance and more discipline in approaching 3D modelling. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide27.png "Getting Inspiration from Real World Objects")

My first mock-up of a Vector C-Class (Aggressive) Destroyer, complete with circular divisions, bevels, collapse, connect, vertices, segments, and divisions to create a more complex model than in previous attempts. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide28.png "Learned Circularisation With Geometry")

In this workflow I have concentrated only on the Extrude option in the Edit Mesh panel. I first selected the entire cube as normal (so that the entire polygon was light brown) then clicked Extrude. Through some research and trial and error I found that in the polyExtrude pop-up window that appears, the Keep Faces Together option needs to be turned off in this example. Once that’s done the little boxes and planes near the XYZ direction arrows can be used to manipulate the sections of the box. Clicking Extrude again will create a smaller cube within the larger cube. In this example I extruded three times to create this crate / carton model. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide29.png "Multiple Extrusion Processes Across Planes")

Another important shape in modelling – the 3D triangle / pyramid / trapezoidal shapes required for everything from roofing in the Sims to ramps in Motor X. I started out by creating a cube as normal. Then I switched to Vertex mode and selected two adjacent vertices and used the Merge option from the Edit Mesh panel. I repeated the process for two more adjacent vertices and the result was this shape. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide30.png "Vertex Manipulation")

The Delete Edge / Vertex option in the Edit Mesh panel removes any edges and their corresponding vertices – a handy tool when working with specific polygon shapes and edges where vertex count is a factor. It is of course also extremely useful in further refining the polygon as I discovered with further experimentation. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide31.png "Detaches and Extrusions")

Once Delete Edge / Vertex has been applied, experiment with the Detach option in the Edit Mesh panel. By removing the border of the top face of the cube, then applying Extrude to the sides, I was able to create this bathtub / rollercoaster cubicle / fancy shoe etc. Modelling with polygons means having a particular form and function in mind, then getting familiar with the tools to build this out, since there are multiple avenues to reach the same final result. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide32.png "Advanced Shapes from Toolsets")

In this instance I have modified the bathtub from the previous exercise. Using the same tools learned so far, it is possible to now start creating very rudimentary character structures, like this rodent with an ear, eye socket and mouth. Further refinement will result in a more detailed and realistic outcome but the process has already begun at this stage. The key is to keep experimenting to achieve the eventual desired outcome. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide33.png "Restructuring Current Shapes")

The Mesh Tools panel has some incredibly useful options, of which not least is the Insert Edge Loop option. By clicking on this tool, Maya creates additional edges or segments across the vertical and horizontal planes of the polygon. The applications to efficient modelling cannot be overemphasised. The Insert Edge Tool option has additional features in the Tool Settings pane. For example, clicking Multiple Edge Loops will create a set number of equidistant edges to the cube. You specify how many edges you want in the value box below. Once that is done, clicking on the Reset Tool button towards the top of the Tool Settings pane will allow for each edge to be individually manipulated. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide34.png "Mesh and Insert Edge Tools")

Game design requires a strict control over the number of polygons, vertices, faces, and edges to maximise the efficient use of resources. Maya provides a handy feature to keep track of these. Navigate to the top row of menu items and click on Display. From the dropdown menu navigate to the Heads Up Display sub-menu item, then down to the Poly Count checkbox. The menu items in Maya are typically in alphabetical order. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide35.png "Polycount Management")

Continuing towards an ultimate concept, the all-important cannon is an essential component of any action-based story. This cannon was created by placing a cube polygon, inserting edge loops to get the desired shape, then extruding a face to form a protrusion. I then bevelled the leading face of the protrusion and extruded the resulting face back into the structure to create the hollowed-out cannon effect. Further refinement will continue as the module and this project progresses. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide36.png "Essential Games Cannon")

This cannon has quite literally been knocked out from the top and dented on the sides to show it is now out of action. This effect is once again the result of combining all the tools learned so far. I've learned how to model and assign knockouts and incongruent destruction properties and patterns for games assets. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide37.png "Knockouts and Destruction Patterns")

<h1>Week 3: Weeks 1, 2 + Complex Forms, Shaders, and UV</h1>

The concept is to build a robot that is also symbolic of a common practice, in this case a light-hearted jab at toilet humour. The T-Bot 2 Series will hopefully be a convincing enough metaphor for this concept. The first part of the robot – the articulated shoulder and sprocket joint, elbow, arm, and pivot-swing support – have been modelled to resemble the mechanism found within cisterns including the handle, support strut and pump. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide38.png "Conjoined Models with Articulation")

The joint of the reticulated arm created by first extending the length of the arm (in Vertex mode), then inserting an edge loop (Shift + Right Mouse Button; then select Insert Edge Loop) and pushing the edge back to create an elbow. Then extend the forearm vertices and taper using the scale tool. Finally add a sphere and deform its shape into that of an egg and attaching it to the elbow joint. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide39.png "Reticulation Modelling")

I added detail to the spherical joint by selecting faces on the sphere, circularize the selected faces, then begin extruding them inwards towards the joint, to create a suitable depression. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide40.png "Spherical Joints for Robotic Arm")

Arms have been mirrored by duplicating the original (left) assembly and reversing the scale in the Channel Box / Layer Editor pane. The body has been constructed from a cube with edge loops, warped vertices, and smoothening applied. Additional details and dents have been applied through a combination of tools under the Mesh, Edit Mesh, and Mesh Tools panes. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide41.png "Mirroring for Robot Body and Arms")

Likewise, the back of the robot has been provided with a similar anatomy to the front – the indentations at the front provide a consistent ripple effect throughout the back, creating the illusion of a bullet or projectile that has passed through the torso and has resulted in its shape, which is consequently not to mechanical or biological, but somewhere in between; a bionic construct. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide42.png "Backface and Frontface Anatomy")

Leg joints created and attached to the bottom section of the torso. For symmetry accuracy all assets were grouped accordingly (CTRL + G) then positioned by inserting values into the Channel Editor / Layer Settings numeric boxes to mirror each asset’s counter position. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide43.png "Torso and Hip Joints")

Through a few (actually many) YouTube tutorials I have (to some extent) figured out the bend deformer tool and its application to making assets like pipes, hoses, wiring etc. No toilet concept is complete without plumbing and the exercise to find, create and manipulate pipes will no doubt be a useful skill to learn for future modelling projects. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide44.png "Curves for Pipes and Hoses")

Toilet Robot (T-Bot 2 Series) model – replete with hose and air filter funnel – getting close to completion. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide45.png "Basic Robot Form")

The main torso has been modelled to look like the portable toilets one finds at construction sites and large public gatherings. The extra allusions have been added by way of the squatting posture, freed up arms for reading, and the coin slot at the back – all of which (hopefully) render the concept of the daily visit. A few future additions might include allusions to a magazine rack holder and a drain-like shape for increased association. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide46.png "Posture and Poise")

Additional textures have been added to the toilet robot, along the lines of the “Toilet Zone” look and feel. Here I have learned to apply nodes and chamfer vertices to create a more textured and asymmetrical look. Using the hypershade tool I have also managed to vary the vertex spacing and extrude depths to create imbalanced albedo levels across the model, which I believe will be useful for when I ultimately do a UV wrap and texture. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide47.png "Texture and Topology")

Further detailing done to the body of the model to create a diseased and leprosy-inducing look. This effect is achieved by chamfering individual faces and extruding / deforming each face to create the pimply, diseased-growth look. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide48.png "Deform Tools")

Further improvements to the robot were done here by isolating specific sections of the body and manipulating them through the basic command tools (bevel, extrude, bridge etc) and through the mirror tool where symmetry is required. The mirror tool was used to mirror along the objects mode rather than the world mode, since the robot’s position and construct is ever so slightly asymmetrical. Further refinements have been carried out to the front façade to increase the derelict quality of the robot and the scene it will operate in. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide49.png "Combination of Tools for Modelling Facade")

With the toilet bot nearing completion, the environment around it is under construction, in this case a modern water closet, complete with counter, sink, faucets, mugs, shelves, and towel rack. The robot standing to the side is in fact the cistern, which hopefully adds to the narrative tension of this scene. The walls, fixtures, and fittings for the structure were built using grid snaps, live interaction, and the list of common tools. I have also changed the background from flat grey to the default gradient since the scene is moving from a flat two-dimensional plane to a more three-dimensional construct. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide50.png "Environment Construction")

The colouring process with shaders – so far I have managed to apply blinn, phong, and materials and anisotropic shaders to the walls and fittings. The robot will come later. The shaders can be found under the Rendering shelf of the top toolbar in Maya. It is important to use the Outliner pane (left of the screen) to properly label all assets since the more shaders and details in a scene the more complex is the workflow and process management. After this stage will come Arnold. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide51.png "Shader Applications")

To copy-paste an existing object’s shader to apply to another object, right click the object that requires shading. From the corresponding dropdown menu, locate the Assign Existing Material option, and from the flyout tab choose the shader that has already been applied to the first object, for use on the latter. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide52.png "Shader Toolbars")

After finding a suitable image of a texture online, and importing it into Maya (in this case the flooring, which initially had a blinn applied to it, but after clicking on the checker box icon near the blinn, an image can be uploaded to Maya) the flooring is ready for UV wrapping / unwrapping. The thumbnail of the red and white carpet texture can be seen in the image above. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide53.png "Texture Mapping")

This is in UV editing mode (from the dropdown menu at the extreme top-right corner). Select UV Editing from the dropdown. The layout here shows the file that has been imported with corresponding UV values from 0 to 1. This UV Editing layout screen can also be reached from Windows > Modelling Editors > UV Editing. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide54.png "UV Mapping")

Here is the carpet texture that was imported from the last step. The texture can be brought up by clicking on the face / surface / object that the texture was uploaded and assigned to, from the previous step. The white inverted T is the UV wrapper, which is in fact the six sides of a completely wrapped cube. Note: the UV is a flattened-out version of the object that needs to be wrapped along a box model. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide55.png "Flattening Maps")

Clicking on the checker map button (the two buttons in line with the right of the UV box in image above) will bring up the UV checker screen with corresponding coordinates and values. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide56.png "UV Co-ordinate Values")

Of the six empty spaces in the inverted T, one of them contains the texture. To see which one, right-click the asset from the screen on the left (in this case the floor) and the UV layout on the right will highlight (in green) which space contains the texture. In almost all cases it is the third box from the top just before the horizontal bar of the T. If for any reason the texture is not showing up, as is the case here, click on the scene on the left, then press 6 on the number pad to bring up the texture view. Note that assigning the texture in this mode will do a complete UV wrap of the object. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide57.png "UV T-bar Mapping")

Assign a new UV by clicking on UV (from the top menu) then select planar in this case since the surface is flat. Consider the shape of the asset before assigning a cylindrical, spherical or planar UV. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide58.png "Assigning New UVs")

Selecting planar has assigned a brand new set of UVs to the flooring of this scene. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide59.png "Planar View")

Success! The carpet texture has been applied to the floor as a UV. In the next step I will download a painting to map onto a frame on the left wall, following the same procedure described above. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide60.png "UV Map Completed")

Here is a painting UV wrapped onto the face of simple cube that has been reshaped to become a frame. UV wrapping requires creating a new set of UVs to fit with the inverted T as described. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide61.png "UV Map of Painting")

The scene is coming along nicely now that UV wrapping has been added. In the following sections I will be adding shaders, textures, and UV wraps to the robot, which will likely be the most detailed (and rewarding in many ways) work of this project. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide62.png "UV Map of Environment")

In this scene I have added a proper carpet texture through the UV wrap tool and also created a wicker basket for added practice with UV tools, following the same procedure learned so far. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide63.png "UV Map of Wicker Basket")

<h1>Week 4: Weeks 1, 2, 3 + Full Scenes, Arnold, and Rendering</h1>

THE ROOM: Here is a new scene I am creating, from scratch, to apply everything learned so far. I have subscribed to a few tutorials on YouTube as well as Udemy (which is more structured) that teaches the basics of shading and UV wrapping using Maya 2017. I am using Maya 2018, but the tools are largely similar. I will be creating a low poly scene. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide64.PNG "Modeling a Room")

I have built the furniture in this office scene (chair, desk, laptop, mugs, books, picture frame, window, and whiteboard) using the techniques described in this document. I then applied a lambert shader to the two walls and set the colour. Shelf and desk with shaders (lambert, blinn, and phong) applied. Floor shader (blinn) applied with reflectivity added for rendering and lighting effects, which will follow in the next few steps. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide65.PNG "Shaders Applied")

Multiple shaders applied to different faces of the same object. The vertices, faces, and edges can all be manipulated individually for any action being carried out, from applying shaders to UV wrapping. I have even managed to allocate shaders to the window panels for added effect.![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide66.PNG "Lambert Values")

Shaders applied to all objects, including individual book pages, which carry the same lambert values, whereas the covers for each possess varying blinn shaders. The next few steps will be UV mapping, followed by lighting, then rendering using Maya’s inbuilt render as well as the Arnold rendering engine. Tip: to apply the same shader to other objects, right click on the object that requires shading, then holding down the right mouse button scroll down the menu to the Assign Existing Material option. From the flyout menu pick one of the shaders that has been already been applied. Throughout this process do not release the right mouse button. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide67.PNG "UV Wrapped Picture")

A UV wrap has been assigned to the picture hanging on the wall, in this case an image of Marina Bay Sands in Singapore. The UV wrap is done by first uploading an image to the sourceimage.exe file as this is where Maya looks for files. Then go to the UV Editing option from the dropdown menu on the top right. Identify the box from the inverted T which contains the face that will hold the image and assign the UV wrap. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide68.PNG "Phong Shaders")

 Window with see-through glass added using a phong shader with transparency. I played around with the sliders and settings. Maya does a good job generating the effects in real time. In this scene the glass has almost maximum transparency with moderate levels of reflectivity, specular colour and reflected colour applied. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide69.PNG "Transparency Settings")

Once the basic modelling is complete it is time to render. I have set up a camera by going to Create > Cameras > Camera. This generates a camera within the scene. Position the camera then go to the Panels option in the dedicated window bar and choose ‘Look Through Selected’. The scene is now being viewed through the camera that has just been created. Also click on the little icon that says Resolution Gate to view what the final output will look like, and what dimensions, in this case 960 by 540. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide70.PNG "Camera and Render Settings")

Choosing the camera’s Focal Length can alter the perception of the scene. In this example I played around with the values to find the best composition for this scene. To get to this window, click on ‘camera’ in the Outliner panel to the left, and make sure the Attribute Editor is active in the right panel. Tip: to avoid accidentally shifting the perspective and reconfiguring it, lock the camera’s settings by clicking on the little icon with the camera and lock symbol, located at the top of the dedicated window, under the View, Shading, Lighting, Show, Renderer, Panels bar. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide71.PNG "Camera Focal Length")

In this scene I have created a light (the first step towards final rendering) by going to Create > Lights > Point Light. Just like a polygon object, the light asset will be generated in the scene. View the effects of the lighting by clicking on the little icon with the bulb symbol, located at the top of the dedicated window, under the View, Shading, Lighting, Show, Renderer, Panels bar. Using the now familiar move / rotate / scale tools the light can be positioned and adjusted as required. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide72.PNG "Lighting a Scene")

View the shadows generated by the point light by clicking on the little icon with the sphere and shadow symbol, located at the top of the dedicated window, under the View, Shading, Lighting, Show, Renderer, Panels bar. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide73.PNG "Shadows and Casts")

In this example I have removed the point light and placed a spotlight with tweaked values for the cone angle, penumbra angle, drop off and shadows – all of which can be found in the Attribute Editor panel on the right. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide74.PNG "Tweaking Light Settings")

I have now started using Arnold lighting systems. In this case I have used the area lighting option from the Arnold top menu dropdown. This is the Arnold render window, which can be reached by clicking on the little icon with the scene clapper and eye in front of it, located just below the top menu of Maya. Each light can be hidden and shown separately to see individual effects by choosing the light in the Outliner panel and toggling the light on and off by using the H key. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide75.PNG "Arnold Light Settings")

Final mood setting for the scene has been set with a directional light and an Arnold area light. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide76.png "Directional Light")

Render settings set under Options > Render Settings, within the Arnold window itself. Bump up the Camera (AA) value to maximum, i.e. 10, then click the Render button, which is the scene clapper icon located at the top left of the Arnold window. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide77.png "Render Settings")

Final render in progress – the process may take several minutes, even on a powerful computer. The first render on my computer (Alienware 15.6 inch laptop running 32GB, 512GB SSD, 1080 Graphics Card, i7) took 2:23 minutes. I was unhappy with the first render owing to particles in the atmospheric lighting oculus and so I revisited the atmosphere settings, (Render Settings > Environment > Atmosphere) clicked on the link icon for atmosphere, and bumped up the samples from 5 to 33. The second and final render took 9:16 minutes. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide78.png "Arnold Render Settings")

But the results were much better, and the additional wait of just under 7 minutes was worth it. To save an image of this final render, first go to File > Save Image and click on the information box to the right of the Save Image option. Ensure that the Colour Managed Image radio option is checked to preserve gamma information. Click on Apply and Close. Then revisit File > Save Image and choose the format of your preference. Choose PSD, tiff or targa (to preserve alpha values) if you want to do post-modelling and post-rendering work in Photoshop. I saved my final image as a PSD and then again as a PNG. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide79.png "Second Render Process")

Here is my final image in PNG. This entire scene and all its assets have been built entirely from scratch in Maya. Four weeks ago, I had never opened or even touched any 3D modelling software, ever. So even though I hope to get better, I am rather happy with this outcome. This result is a matter of following what is being taught in the lectures (credit: Mike Williamson), doing plenty of practice and research, and asking all the stupid questions in the world to anyone who is willing to answer you. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide80.png "Final Environment Render Output")

The lighting from Arnold together with the texture and UV mapping on the furniture create this mysterious 1940s detective movie look, complete with the art nuevo chair and desk that characterised the 1960s. Moving further along the skewed time line, the introduction of the modern laptop bridges the scene with the contemporary era. I believe that games are narratives in their own respect and each scene ideally requires a degree of genre to reinforce gameplay across both the experience and the story. This is also the underpinning foundation for ludology.

<h1>Week 5: Weeks 1, 2, 3, 4 + Structures, Materials, and Narratives of Reality</h1>

THE ENERGY BUILDING: Here is a new scene I am creating, from scratch, to build on everything learned so far. The concept is to create a New York style building from the 1940s and add complex shapes that are from differing eras all the way through to the present and future. In this project I wanted to construct a typical New York 40s-era building, then give it a futuristic, self-sufficient urban energy generator. I have tried to increase the complexities of the model in this scene. Using extrudes and bevels together with chamfers and vertex points, I have managed to warp faces into custom shapes that I have then bridged using the Bridge tool with settings set to Smooth + Curve. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide81.png "Energy Building")

The generator wheel at the back of this energy-efficient building has multiple points in tandem protrusion – the kind one sees in wind turbines. This was achieved by adding divisions along the thickened perimeter of the wheel then pulling out each face in series with its counter divisions to get this symmetrical but non-aligned look, which is the principle behind turbines – they are not aligned deliberately to break even patterns of wind flow. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide82.png "Wheel and Hypershading")

THE APPLE: Here is a new scene I am creating, from scratch, to add more complexity to a simple object by using more tools in Maya. In this project I will try to create an apple using all the tools learned so far, together with a few new tools I have discovered from online tutorials, namely soft selection, hypershading and bump mapping. In this scene I have created the basic sphere which serves as the foundation for the apple. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide83.png "Basic Apple Sphere")

Double-clicking the move tool (white arrow in the left menu bar) brings up the Tool Settings menu. Scroll down to the bottom of the menu and click on the checkbox next to Soft Selection. The soft selection tool essentially creates a fall off for the amount of manipulation carried out on an object. Instead of just affecting one selected vertex point or edge, it also affects the points around it in varying degrees of force, shown by the coloured mesh lines. The fall off amount can be adjusted by using the sliders. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide84.png "Soft Selection Tool")

The soft selection has been applied to the top and bottom of the sphere to create the depression found at the poles of the apple. I have also selected random points along the sphere and used the scale tool (R) to adjust the symmetry of the sphere. It requires a few takes and pass-throughs (hint: the x-ray tool comes in handy) to get the ideal form. The resulting shape is much more like an apple. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide85.png "Applied Soft Selection to Poles")

Blinn applied to the shape to create some reflectivity and waxy appearance. Once the blinn has been applied, first set the texture for the object – in this case an apple skin made in Photoshop or acquired legally from an online source. Once the texture has been applied the specular highlights can be adjusted to get the shine required. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide86.png "Blinn Shader Applied")

The green apple skin texture has been applied to the shape and already there is a fairly realistic model. The next step is to adjust the specular highlights, lighting and angle. A stem will also be added to the model and adjusted accordingly. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide87.png "Texture Mapping Applied")

A cylinder has been added to the scene, which will then be adjusted to create the stem for the apple using the tools found under the Edit Mesh panel. Since stems are seldom perfectly straight or symmetrical, the use of the extrude, bevel and bridge tools will come in handy. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide88.png "Stem Applied")

The cylinder by default has 20 sub-divisions. This makes it hard to select all the faces. Under the Channel Box / Layer Editor panel, click on the poly shape to bring up the settings. Then slide the number of divisions down to a more reasonable number – in this case 9. These sub-divisions can always be amended later in the same tools panel once the shape is finalised. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide89.png "Stem Shaped")

Final shape of stem is in place. The shape of the stem was achieved through extruding the face multiple times, and in each step I tilted the face to create the bending look. In the final extrusion I selected the edge and scaled it up to create the tapering stem look found on most apples. All of these tools can be found in the Edit Mesh tool panel. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide90.png "Final Stem Shaped")

A lambert shader has been applied to the stem and a bump map has been applied to the sphere. The bump map can be found under the Colour section of the blinn / lambert section in the Attribute Editor. The default value of the bump map makes the apple look shrivelled and old, which has its own benefits depending on what the aim of the scene is. In this case I want the apple to look a few days old – neither too fresh nor too decayed. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide91.png "Shrivelled Apple Form")

Under the bump tab there is a Bump Depth slider that when adjusted provides fine control over the amount of bumping / texturing on the object. Through trial and error, I found that a value of -0.020 works well for the type and age of apple I want to create. For an orange the bump value will be higher since the orange skin is more texturized. I also applied a bump map to the stem of the apple to create a more gnarled look. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide92.png "Ripe Apple Form")

Using the Arnold Renderer to render the final scene, learned from the previous project with the room. Because the shape and assets are simpler the same render quality settings results in a much faster render of 0:21 (21 seconds). Directional lighting and area lighting were used here (refer to the Room project) to provide additional depth to the final image. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide93.png "Rendering Final Output")

The final render of the apple. From sphere to apple the process becomes more familiar as I practice creating different scenes with ever-increasing complexities. It is amazing how the same tools used for creating simple shapes are constantly utilised (and fine-tuned) to create more advanced projects. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide94.png "Final Render")

<hr/>
<h3>Writing Shaders: Integrating Modelling with Programming</h3>

Game engines only draw triangles; the GPU does only one thing, which is to draw these triangles. Programmers decide the position of these triangles, and their colours, using shaders. In Unity, there is a shader gallery. A CG shader is a custom shader where all the lighting is controlled, whereas an albedo shader provides more control. When creating effects use an albedo shader; when creating post-effects, it's better to use a CG shader.

Shaders can be used for a variety of purposes, without writing a single line of code. They do not use any JPEGS on PNGS. Everything is procedurally generated when using shaders. A good example to see shaders in action is the website: glslsandbox.com/e GLSL is what runs on mobile phones, chrome cast, televisions etc. GLSL shaders can also be written in Blender and Unity, to design effects. The website holds an older version but is useful to understand how shaders work in a procedural method when applying these to objects and games assets.

Each scene contains nodes, which contain a matrix (as well as child nodes). Attached to these nodes are geometries that can be adjusted as required. When dealing with nodes, note that these nodes refer to geometry (triangles). Uniforms are materials that are same for the entire model that is being created. Clara.io is a web-based 3D modelling tool with plenty of shader options, and uses nodes to draw each scene.

The triangles in the FBX model go through a vertex shader, which provides the opportunity to move things around by (1) scaling or rotating, and (2) perspective transform, which makes objects look closer or farther away by dividing across the distance. The three corners of the triangle are fed to the rasterizer to create fragments. The rasterizer decides which pixels are included in the triangle. The fragment shader chooses a colour. The depth buffer figures out if the object can be drawn, and the frame buffer holds the colours. Fragments and pixels are used during anti-aliasing for multisampling. Mobile GPUs are optimised for multisampling, in which case having smooth edges on triangles requires fragments inside the pixel. In films, each pixel is run 500 times during multisampling, as opposed to about 8 times for mobile phones.

Geometry essentially is a set of triangles created in 3D software, then exported in FBX files. Normals are an essential part of this geometry. A bi-normal is added during bump mapping and UV mapping. Normals can also be baked into attributes, to create maps that blend into textures. For example, a map can be of a forest, and another map used as a path through the forest. Both these maps can be blended with each other to create smoother integration. Note that maps are bigger than attributes and should be managed accordingly. Two textures can be multiplied together to cover an repeats in the texture or map. Vertex attributes and custom maps are then fed into the shader.

Vertex shaders allow changes in shape, position or rotation of the geometry. Without a vertex shader, the geometry of modelled objects will always be at (0,0,0) and therefore will not move relative to the camera. Vertex shaders are used to step the objects around. Instancing is used to render a model several times over with slight changes in characteristics. Therefore an army of elves, for example, can be created by using just one instance of the elf, with minor attributes changed. UV co-ordinates can be transformed to animate the textures. Vertex shaders can be used to change the UV co-ordinates. Vertex shaders are also the only place where the size or shape of the object can be changed. Vertex shaders are mostly about shape.

Fragment shaders decide which colours to draw, and also the depth used in each colour. Multiple colour buffers allow for the creation of additional effects. A fragment shader can be used to create a plane that separate dark and light sparkles, for example. The plane then sweeps through the scene and changes one sparkle type to another. The same effect can be used for the effect of changing wireframes to fully-detailed models.

Lighting is also done using fragment shaders. Reflection maps and probes are used more commonly to create additional interest. The normal is just used to turn the reflection vector into a cube map, which can then used to create a diffused, specular map, for example, which creates a lighted effect. The opposite procedure can be used to turn a room dark. Dot products are used to calculate light intensity. This is illustrated in the example of a racing car with the roof reflecting the sky. The reality is that the map is used across the entire scene and lit up at certain camera angles to the normal.

Physically-based rendering mimics the way that rendering occurs in films. However, due to computational limits, PBR is seldom used in games owing to time and materials constraints. In games, PBR mostly refers to using reflection probes and environment maps for diffused and specular shading. Disney, for example, produces more games than any other studio. A paper out of Disney addressed this issue of PBR and its applications (limited in scope by the current state of technology) from films to games. Physically-based games essentially refers to blended compositions of parameters such as reflection maps.

Diffuse shading is the reflection from a rough surface, whereas specular shading is the reflection from a shinier surface. Both characteristics are used in 3D modelling software. Ambient occlusion refers to the corners of a room or quadrant. Ambient occulsions look for corners in the depth map and shades them darker than elsewhere in the room. Ambient occlusion is often confused with the edges of objects but works well for the human eye since these minute differences are not very easily spotted. All three options are available in Blender, Maya, 3D Max, Unreal Engine, and other industry-level 3D modelling software and games engines. Distance maps are a very handy way of working out full ambient occlusion. A distance map is a voxel of the entire room, which then uses rays to very quickly determine ambient occlusion.

Shadows in games engines are used in a particular way: the camera is used to determine how the light itself can become a shadow. The light source, from the point of view of the camera, tells a player which parts of the object will have positive lights, and which will have negative lights, or shadows. This is why walls in a game need a critical thickness, so that the shadow asset does not pass through it but stays on it. As a general rule, chamferring is a good way to overcome many shadow issues. Z-buffers are a bunch of numbers that state how far a triangle is from another. The Z-buffer determines this order and decides which ones to affect, based on the shape required.

Tesselation shaders are another option to create smooth surfaces. However, geometry shaders allow for the creation of further points, which is not possible in vertex shaders. But mostly the games industries use vertex and fragment shaders. Tesselation shaders are also used for nurbs curves and smoother geometry, but games still tend to choose triangles owing to its flexibility.

Compute shaders are used to calculate processes between shader creation cycles, and are most often used for film production and post-processing. These are useful for tracking detailed changes during the shader creation process.


<hr/>
<h1>Week 6: Weeks 1, 2, 3, 4 + 5 + More Narratives of Reality</h1>

THE CERAMIC STRAWBERRY STATUE: Here is a new scene I am creating, from scratch, to add to the previous two projects. In this project I am going to try to model a ceramic strawberry counter ornament based on everything I have learned so far. To start off I have created a sphere and then by double-clicking on the move tool (white arrow) I clicked on the Drag select radio option box. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide95.png "Ceramic Strawberry")

Here is the basic elongated sphere of the strawberry’s shape. The sphere was elongated using the scale tool (R) and the highlighted section of the mesh was selected using the drag tool as described in the step above. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide96.png "Ceramic Strawberry Basic Shape")

Hitting the shortcut key B brings up the soft selection option as shown in the image above. The soft selection description, function and usage processes are outlined in the previous project on modelling an apple. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide97.png "Soft Selection")

The overall shape has been fixed and the vertices and edges at the top of the strawberry have been ranged and pitted using a combination of points and toggling between scale and movement using soft selection and the drag tools to create the rippled effect out of which the strawberry leaf will come. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide98.png "Ranging and Pitching")

With all the current (straight) edges selected, go to Create > Sets > Quick Select Set and create a new set for these edges. Call it anything. I called my set Straight-Edges. The reason for Quick Select Sets is to create a specifically selectable group that can later be easily isolated when intermingled with other edges, faces, vertices etc. Later these straight edges will need to be removed to create the dimples in the strawberry. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide99.png "Quick Selection Set")

To create the dimpled effect of the strawberry I selected all the faces of the object by clicking and dragging over the model then went to Edit Mesh > Poke. This creates interstices across the faces of the model. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide100.png "Dimpling")

Only the new criss-crossed edges that resulted from the Poke tool are required. Therefore, the straight edges need to be deleted. Since selecting each straight edge would be incredibly time-consuming, the fast and easy way is to select the Straight Edge set created earlier using the Quick Select Set tool. Go to Select > Quick Select Sets > Straight-Edges to select just that group of edges. Then go to Edit Mesh > Delete Edge / Vertex. What is left behind are the criss-cross edges, as required. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide101.png "Poke Tool")

Here I have created a Quick Select Set for all the chamfered faces that will become the pits for the strawberry, called Pits. These individual faces can be achieved in several ways. I bevelled the faces of the entire strawberry, then chamfered the vertices to create these individual and somewhat evenly distributed face markers across the shape. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide102.png "Chamfering")

Go to Edit Mesh > Extrude and push the selected faces (Pits). Pressing G while in Extrude mode will create another extrusion layer. I created three additional extrusions to create this multi-layered pitted effect. Play around with the number of extrusions to get a feel of how much is too much and what feels just right. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide103.png "Pitting Completed")

When the shape feels satisfactory it is time to add a new texture. Right click on the object and scroll down to Assign New Material. I added a blinn to this object and changed the colour to a simple red as shown in the next image. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide104.png "Blinn Applied")

The blinn has been applied and a red colour assigned that matches a strawberry hue. At this stage, where refined selection is required the use of the Quick Select Sets tool is invaluable for efficient workflow and processes. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide105.png "Colour Hue Applied")

Here the pits have been selected using the previously-created Quick Select Sets tool. I have applied a blinn to the pits and stained them with a slight orange for greater contrast since the organic fruit has darker pitted stains whereas with ceramic the pit details tend to reflect more. The object is starting to look more like a strawberry, especially when it is scaled down. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide106.png "Shader Applied to Pits")

In this step the stem is inserted. Create a simple cylinder and drag it to the top centre of the strawberry, where the wrinkles curve down towards the centre, just like in a real strawberry. Ceramic objects usually have more linear wrinkles owing to the material and so I have deepened the grooves at the top where the leaf comes out from. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide107.png "Stem Created")

Select and delete the bottom and side faces of the cylinder so that what is left is a flat plane. Using the drag select tool is extremely handy for this process. Since this is intended to be a ceramic object, I have included a seam across the upper-middle section of the object to show where the kiln connection would have been during the firing stage. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide108.png "Flat Top")

With the flat plane selected, hit 3 to add divisions and round off the cylinder. Then go to Edges, click on the outermost edge and using the move tool, fold the edge down and over the strawberry to create the umbrella-like dome. Do this for a few of the edges towards the outer circumferences of the cylinder plane. Then switch to Vertex mode and select the centre vertex of the plane. Using the move tool push down the vertex to create a depression. Essentially just play around with the shape until it feels right. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide109.png "Cover Lid")

Once the shape is finalised, pick an image as a UV texture – in this case I have used an image of mint leaves – to act as the top stem of the strawberry. Apply the UV map as detailed in the previous projects (Rooms and Apple). Use the UV Shell select option to move and scale the UV shell over the texture image to achieve a satisfactory result. Duplicate the texture to create more interest. Because this is a fired ceramic object, no bump map has been used. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide110.png "UV Map on Lid")

I played around with the lights to see if I could create a more ceramic effect instead of an organic fruit look. In this project I wanted to create fruit furniture as a combined practice between the furniture in the Rooms project and the fruit in the Apple project. By adjusting lighting and blinn effects I was able to create this ceramic-looking strawberry statue. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide111.png "Lighting and Rendering")

Here is the final render of the organic strawberry ornament. The inclusion of the kiln seam towards the upper-middle of the object deliberately gives it a manufactured look. I initially thought I could achieve the dull, glassy effect of fired ceramic using only lighting, but over the course of this project I have learned that when it comes to materials, the formation of textures requires that every stage, from the basic skeleton right through to the final lighting requires as realistic a treatment as possible. The final result can be used as either a stool or an urn or jar. ![alt tag](https://github.com/arjunkhara/3D-modelling-repo/blob/master/images-weeks-1-5/Slide112.png "Final Render")

Here is another final render, this time of a barbecue stove. This barbecue stove model was made using the same principles for materials and texture realism as in the strawberry ceramic jar section, then further refined to imbue the model with its own characteristics. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/BBQ-Stove.jpg "Final Render")

Likewise, the following images of a paint can, and a chair, were all carried out in a similar fashion. It is important to note that while each model requires its own set of attributes and characteristics, the methods and approach to modelling remain consistent across projects. Organising workflows, regardless of the object itself being modelled, is of paramount importance, especially when moving out of Maya's environment and into external programmes such as ZBrush and Substance Painter. Here is the final render of the paint can. 
![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Paint-Can.jpg "Final Render")

Following the methods and approaches used in the Introduction to Modelling course helps clarify these approaches by offering a consistent way of thinking and performing. For the chair, I started out just like the previous projects - to first understand the form of the chair in as few strokes and elements as possible. From there, every additional stroke is an embellishment designed to reinforce, but not create, greater realism and model integrity. Here is the final render of the chair. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Chair.jpg "Final Render")

<h1>Week 7: Weeks 1, 2, 3, 4 + 5 + 6 Complete and Complex Scene Modelling</h1>

THE AUTHOR’S CABIN: Here is a new scene I am creating, from scratch, to add to the previous projects so far. In this project I am going to try to model an old, cabin desk reminiscent of a writing room from the 18th century. Inspiration, tutorials, and references for this scene are from Udemy tutorials, YouTube videos, and two books. All sources have been referenced at the end of the page. The Mesh tool has everything for object manipulation. The Edit Mesh tool has everything for component manipulation. The Mesh tool performs different functions for modelling and fine-tuning. The Mesh Display tool has everything to do with normals and vertices – how the object looks. Curves tool contains nurbs manipulation. The Surface tool is used to create nurbs surfaces, then polygons from them. The Deform tool can be applied to change the shape of objects in Maya. The Generate creates lots of geometry for a vast-view scene. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide113.png "Started New Scene of Cabin")

To select entire parallel edges, click on one edge, then SHIFT + Double Click on an adjacent edge to select the entire ring of edges, which can then be manipulated, eg extrude or collapse. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide114.png "Beginning With Cubes")

To grow or contract a selection, hold down SHIFT + > to grow the selection, and SHIFT + < to contract the selection. This works for all selection types, i.e. faces, edges, vertices. This is critically important to have proper topology for the model to shape adequately. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide115.png "Edge Contractions")

All authors use candles in one form or another in their writing, from basic lighting in the past, to religious and superstitious reasons. Here I have reshaped the cube into a candle using a combination of the basic tools together with soft selection (hit B) and the Crease Tool (select an edge, then hold SHIFT + Right Mouse Button to bring up the Crease Tool, then use the middle mouse button to drag and shape. More crease tool applications will result in the dripping wax look. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide116.png "Candle With Wick")

In addition to the candle, I am also building out a book. A basic cube has been manipulated using the Extrude and Scale tools to create the rough shape of the book. The pages or inserts in books from the 18th century are always smaller than the hardback cover. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide117.png "Book Shape")

Multiple edge loops have been created along the insert using the Insert Edge Loop tool options. These will be manipulated to give the spine of the book a rounder look and therefore a more realistic feel. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide118.png "Basic Book Form")

The spine has been rounded by first selecting the four centre vertices along the edge view of the book. Then holding B and dragging the mouse outward, the appropriate vertex points have been assigned to the soft selection tool. Then use the move tool to pull the selection outward. However, the bend is not following through all the way to the edges. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide119.png "Book Spine")

The lattice tool is a better option. Bring up the lattice tool by first selecting Deform > Lattice and clicking on the options box. Then reduce the number of divisions (by default Maya applies a specific division count) to just one in the middle. Select the lattice points on both sides of the spine (far end and near end) then use the move tool to push these out. The lattice tool will attempt to preserve the shape of the cube, thus creating a sharp point. To create a smooth curve, go to the Attribute Editor, select the lattice tool tab (ffd1) and turn off the local check box. The lattice protrusion will now follow a smooth curve as shown in the image above. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide120.png "Lattice Tool")

Old books were hand-cut, which meant visible imperfections along the page edges. This effect can be achieved in Maya using the Transform tool found under the Edit Mesh panel. Increasing the Random value in the Channel Box / Layout Editor will increase the random distribution of force applied to each vertex. Ensure that vertex mode is selected. Then use the move tool to drag out the selected vertex points. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide121.png "Imperfection")

Here the transform component tool has been applied the vertices along the page edge and pulled in different directions at varying forces to create a rougher, hand-cut look for the book. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide122.png "Rough Cuts")

Mild transform / randomness has also been applied to the top wrapping cover of the book, since this is the area that takes the brunt of any impact when a book falls or is forced into a shelf space that is too small for it. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide123.png "Corner Damage")

In this scene the book’s edges have been bevelled and segmented, and the top and bottom edges of the spine, which hold the inserts between them, have been creased with hardened edges applied. The result is a much more convincing 18th century tomb, than the more modern looking dictionary-type volume in the image immediately preceding this one. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide124.png "Applied Bevels and Segmentation")

Randomness has also been added to the creasing along the leading and trailing edges of the book bind for greater visual detail. This was achieved using the crease tool, then creating a few edge loops and applying random soft and hard edges to each loop. Slight extrusion and movement were also used to fine-tune the effect. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide125.png "Applied Bevels and Segmentation")

For further refinement I have created this dented book corner, a common feature found on old books. This effect was achieved by first creating random edge loops around the area, then selecting all the vertex points at the corner and averaging them out. The result is a dented look that adds a touch more accuracy to the scene. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide126.png "Corner Dents")

Similar effects have been applied to the candle to achieve the convoluted shape that candles adopt when burnt over extended periods. I will add the dripping wax to the candle at a later stage. For now, the deformities and imperfections achieved on the book have also been applied to the candle to evoke the basic feelings of use and agedness. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide127.png "Candle Aging Look")

Another book has been created using the same techniques. This latest book, sitting atop the earlier one, had chamfers and averages for its vertices applied – both along its spine and edges, and across its pages. The result is a more hand-bound feel, which will hopefully come through more at later stages of its development, especially during UV wraps and lighting. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide128.png "More Books")

This candle holder was created from a cylinder with edge loops placed evenly across to provide additional extrusions, bevels, and protrusions. I used a CV curve to draw the primary handle, and the bridge tool to create the small secondary clutch at the base of the candle holder. The CV curve tool is proving extremely useful. To access the CV curve, go to Create > Curve Tools > CV Curve Tool. Draw the curve along the points required. In this case I drew the curve starting from the base of the candle holder. When I was happy with the shape, after adjusting the curve points, I selected two faces at the base of the holder where the curve made contact, together with the curve, then applied the Extrude tool. Finer adjustments were then carried out with the scale, chamfer, and move tool. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide129.png "Candle Holder")

The candle holder is ready after lots of minor tweaks and tugs at the faces, edges, and the curve that forms the handle. The candle requires more work but its position on the candle holder works well and the scene is coming together quite nicely. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide130.png "Candle and Candle Holder")

For more refined work on the candle – the melted wax and uneven burn drips – the sculpting tool is extremely handy. To get to the sculpting tool, click on the Sculpting tab on the top menu bar, then choose any of the orange and white tools. I began by selecting the first one, called the Sculpt Tool. Double-clicking on the same tool’s icon in the left pane brings up the tools options and controls, which I will be using to sculpt the faces of the candle. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide131.png "Waxy Look")

I have created a flame for the candle using the create polygon tool, located under Mesh Tools. The tool acts like the pen tool found on image manipulation software. I drew the shape of the flame using the tool’s points, then positioned the flame on top of the candle wick using the common move tools. It also helps to switch between front and perspective view for accurate placement of assets in the scene. Clicking Alt + B cycles through different backgrounds of the screen. It makes it easier to see and isolate specific items. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide132.png "Candle Flame")

I am learning to use the nParticle tool to create the candle wax drip effect. First, switch from Modelling to Fx in the dropdown menu at the top left. A new set of top level menu options will come up. Click on nParticles, then from the dropdown menu go to Create Options > Water. This will ensure a nice blobby look. Go back to nParticles, then from the dropdown menu go to nParticle Tool. The accompanying tool pane on the right provides fine control over the distribution and spread of the particles. Click and draw around the object with the mouse – though a tablet works much better. Once done, press Enter to commit the tool application. Then, from the top level menu (still in Fx) click on Modify > Convert > nParticle to Polygons. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide133.png "nParticles Wax")

Here is another set of nParticles, used for the wax that drips and accumulates at the base of candle holders. It is important to remember to delete the history of the nSurface polygon history (Channel Box > Edit > Delete History) to leave on the pure polygon behind, and not additional asset data types that unnecessarily take up space. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide134.png "nParticles Drippings")

In creating a pen for the scene I am using a CV curve to draw the basic shape in, using an image of a pen as a reference. I then used the Surface > Revolve Options menu to create a span curve that wrapped itself around a flat planar to pipe polygon. This created the body of the pen that will go into the scene. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide135.png "CV Curves for Quill Pen")

Here is the pen complete with a nib, hole for ink, and a curved stem for where the quill feather will come. I am learning how to use lofted curves to create a feather-like quill that goes around the main curve of the pen. The CV curve has been used in this scene a few times with good results. I am also continuing to add detail to the rest of the object(s) using all the tools – basic and intermediate – that I have learned so far. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide136.png "Quill Pen Base")

Begin by drawing two separate CV curves around the stem of the pen. Then, go to Surfaces > Loft (tool options) and set the parameters to Quad and General with span for initial tessellation controls. Once the Loft has been created, go to the Channel Box / Layout Editor and adjust the nurbs tessellate polygon count to approximately 450 for a roughly even distribution of faces. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide137.png "Loft Tool")

The result of the steps above is a neat mesh that can now be edited and texture-mapped to provide the quill feather effect. The Loft curve is yet another new concept but I am understanding how it works and what its applications are to the overall concept of modelling. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide138.png "Loft Tool")

All my assets for this scene are ready. Additional fine-tuning will continue as this scene progresses. But the next major stage of the workflow is UV mapping for each of the components of all of the assets. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide139.png "All Assets Completed")

The first book has been fully UV wrapped. In some cases where the spine and part of the covers had additional faces, each had to be UV wrapped individually. In these instances I took the opportunity to wrap similar textures with small differences to add to the hand-bound feel. The book has been wrapped in a leather texture with faces deliberately jutting out (from the modelling stage) to show that the cover is coming loose, as it often does with very old books. This book used a combination of blinn and lambert shaders together with textures. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide140.png "Book UV Wrapping")

Scene setup is more or less completed. I experimented with the camera perspective in order to find the best angle in which to frame the scene. Once settled the camera can be locked into place and then lighting can begin. The quill, candle holder, candle, and desk will each be UV wrapped in succession before any lighting begins. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide141.png "Further Book UV Wrapping and Camera Setup")

I have added a piece of paper and used the Bend Deform Tool to give it a natural page curl. To achieve this effect, create a plane and scale it up as required. Then go to the Deform tool panel at the top, and choose Nonlinear, then Bend. Use the bend tool panel on the right to adjust the amount of bend, in my scene I set a value of 20. Then, use the rotate tool (E) to twist and bend the paper along an axis as desired. This paper fits well with the scene and will get its own UV wrap as well. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide142.png "Parchment")

At this stage I am trying to balance lighting with UV wrap to ensure that neither overwhelms the other or interferes with the overall look and feel of the scene. I am testing the scene with spot lights, directional lights and pinpoint lights (for the candle and flame) to get an idea of how a wintry writer’s task would appear. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide143.png "Wintry Scene Lighting")

In this stage I have learned, from a Udemy Tutorial, to add an image plane and assign an image to it. The image is that of a forest through a window, deliberately positioned to cut most of its detail away, leaving little more than a sliver of a dusty window. I have also learned to use the Color Gain tool to manipulate the look and feel of the image plane to match with the scene I have in mind. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide144.png "Image Plane")

On second thought I decided not to use an image in the image plane but rather model a window natively within Maya. I therefore removed the image plane, and added a background wall and divided the face to cut out a window, which I will later fill with an area light. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide145.png "Discarded Image Plane")

All scene setups, camera angles, UV wraps and workflow are complete. The last thing left to do is to explore the render settings, then render the final scene using the Arnold Renderer. The composition of this scene focuses on the candle as the entry point into the frame, in a narrative that literally sheds light on the subject of writing. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide146.png "Scene Modelling Completed")

The final render took 11:30 minutes at a 10 / 2 / 2 / 2 setting with atmosphere sample at 50. I initially set the density level of the fog at too high a value, which dusted out the items. I caught this in the pre-render tests and managed to scale back the fog enough so that it highlights and signifies, rather than obscure and dull, the assets in this scene. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide147.png "Rendering Process")

Here is the final render of the scene. At the end of the fifth week of modelling, I am quite delighted with my progress. Though far from what game studios, or even my own classmates can do, I am excited 3D modelling. Five weeks ago, I knew absolutely nothing of 3D modelling. The term ‘Maya’ still carried connotations of a South American civilisation. And Photoshop was the coolest explanation for everything I saw, from movies to magazines. To come this far (a relative term, but for me a massive leap) is indeed a worthy experience. Much like the act of writing a book, this scene at the end of week 7 throws into sharp relief the incredible possibilities and impossible potential of 3D modelling. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide148.png "Final Scene")

<h1>Week 8: Weeks 1, 2, 3, 4 + 5 + 6 + 7 + High-Fidelity Realistic Modelling</h1>

THE HEADPHONES: Here is a new scene I am creating, from scratch, a set of over-the-ear headphones, modelled on a pair I currently possess. This project is different from the others in that it will be my first attempt to model a complex real-world object. Inspiration, tutorials, and references for this scene are from Udemy tutorials, YouTube videos, and two books. All sources have been referenced at the end of the page. I started with the most basic form required of a headphone set – the muffler and ear cone over it. This process is part of lesson 1 in the Modelling module, which asks students to draw a cycle in its basic form, using only the most fundamental shapes required (sans any embellishments or additional features) for immediate identification. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide149.png "Headphones Project")

I have used a doughnut polygon to begin the modelling. Using bevel, inset, extrude, chamfer, crease, rotation, scale, and move, the basic muffler cover is beginning to take shape. Further refinement will be carried out to make the ear cone as structurally accurate as possible to the real thing. Note the difference between inset and simply pushing in. Inset preserves the topology of the asset on its surface, whereas the latter changes or alters the topology. Insetting is useful for manipulating additional created assets on the object’s surface, so while inset and pushing appear similar, they are not the same thing. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide150.png "Basic Muffler")

The structure of the left ear cone, muffler, shock absorber, earmuff clip ring, and logo area have been created. As before I have used a variety of tools, all of which have been covered in this document so far. The difference is that after some practice, I am able to fine-tune the output of each tool better with every new project. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide151.png "Ear Cones and Clip Rings")

Likewise, the ear muffler portion of the headphone is significantly larger than the rest of the attachment and requires more attention to detail, especially in the increasing conical value from the logo area, but a sudden yet barely perceptible taper as the muffler meets the earpiece. This is achieved by scaling the muffler in stages, then creasing the final edges near the earpiece, smoothening the crease, then extruding the edge inwards towards the centre. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide152.png "Mufflers")

Because all ear mufflers have some degree of imperfection, owing to the wrapping nature of the installation around a ring, the deformities around the muffler, especially for slightly older earphones, impinges on the ring itself. I have achieved this effect through the Sculpt Tool > Grab Tool, that allows manipulation of individual vertex points. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide153.png "Mufflers")

These particular headphones have a soft-pattern alternating protrusion style around the outer muffler. To remain faithful to the structure of the real thing, I added divisions then selected each individual alternate division. This was time-consuming but necessary to preserve the fidelity of the model. Once finally selected, I grouped them using Create > Set > Quick Select Set and named them. If needed again I can now select all of these points with one click. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide154.png "Quick Select Set for Grating Material")

Once all the individual faces had been selected (finally) I extruded them together, then added additional divisions within the extrude. Because I had previously created a Quick Select Set, I was able to select and reselect all of the faces and experiment with the extrude options till I was able to recreate the actual pattern of the real headset. It is no doubt a tedious process, especially in the beginning if the hand slips and selection has to begin all over again. But the final result is a welcome consequence of this attention to detail. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide155.png "Grating Material")

The earpiece of the headphones is ready, complete with spherical logo, edge, grill, supports, clip joint, and ear muffler. The next step will be to create the counter piece. This can be achieved in a few ways, from mirroring to duplicating, then deleting the history and rotating and flipping the piece. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide156.png "Logo Patterns")

Both earpieces have been created. Since the orientation is important, owing to build-up and grouping of discrete polygons, I grouped one side, duplicated it twice (to preserve the original, for which I can reinstate any histories, if needed) and rotated the counter piece by holding down the J key, and rotating the asset so that it spins in 15-degree segments. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide157.png "Both Cones")

Upon careful examination of the headset, I realised that the two ear pieces never face each other head on at 180 degrees, but rather face off at a slight angle to compensate for different head sizes and the shape of the human ear which tends to taper ever so slightly towards the head where it joins. The supporting clips and head band allow for this slight rotation. To confirm this I examined two more over-ear headphone sets and all of them followed the same principle. As a result I have rotated the headsets to replicate the reality of construction. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide158.png "Rotated Cones")

The headband has been created using a CV curve tool attached to the clip section of the ear piece. I then extruded two faces on the clip section, together with the curve, then increased the number of divisions to allow the extrusion to follow the path of the curve. I repeated the process for the other earpiece. Although mirroring could be used to achieve the same effect, I wanted to redraw the curve again for added practice. However, note that for total accuracy, mirroring is the best solution. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide159.png "Headband")

The headband clip section has been created by first adding divisions to the head band, then selecting the faces around the band and extruding them. Further refinement will be carried out and then the same process will be applied to the counter side of the headphones. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide160.png "Headband Clip")

The headband has been built, complete with padding, clip supports, and the centre groove, which (on my headphone set) is for the wire to loop around when storing the set. Both the tension clip joints on either side of the headband have the grooves that allow for the earpieces to rotate slightly, as mentioned previously in this project. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide161.png "Headband Joints")

Shaders and UV mapping applied to the headphone set. Each component received a different shader, owing the multiple materials used in the headphones. The headband has a rubbery look and matt texture, whereas the grill and logo section are more plastic-metal with greater reflectivity. I have done all the shading in Maya. While other software such as Substance Painter exist to make such projects easier, I have not yet had an opportunity to learn and use these, and so I am challenging myself to make the most realistic scene I can create using all of the tools and options available to me in Maya. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide162.png "Shaders and UV")

The lighting system has been setup to provide a more games-advertising look, which interestingly was what led me to buy this headphone set. I have positioned a spotlight and a direction light to create some atmosphere, and give the headphones a sense of power. The angle of the camera is also playing a role in conveying the presence of the headphones, by creating a down-looking-up perspective. The headphones therefore hold a slightly elevated but by no means unattainable position. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide163.png "Lighting")

Arnold lighting system has been set up. I used a skydome light to wash out the blackness, giving it a slight greyish-green hue that evokes military connotations of strength and ruggedness, which also happen to be commonplace game narratives. I then used an area light with some atmospheric volume to catch the fog around the headphones, which edge the scene with a sliver of mystery. With that I am ready to do the final render. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide164.png "Arnold Initial Render")

I have set my render settings to 10 / 2 / 2 /2 and an output at 1080HD. The Samples in the Atmospheric Volume settings is at 50, and the density has been lowered to 0.012 to provide just a hint of fog. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide165.png "Arnold High-Res Render")

The final render is taking place. The total time taken to render this scene was 10 minutes. I discovered that on a Windows computer, if I only keep the dedicated NVIDIA graphics card enabled, disable the built-in INTEL card, the render goes a bit faster and clearer. I am not sure why this is or whether this will work for all computers. But to try this, go to Device Manager > Display Adapters and keep on the dedicated graphics card enabled. Disable the integrated card by right-clicking on the card in Device Manager and choose the disable option. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide166.png "Adapter Settings")

This is the final image render without any Arnold-driven lighting effects, spread on a white background. This was rendered using the Maya Software engine, for quick render to get an idea of what the Arnold Renderer would look like. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide167.png "Adapter Settings")

This is the final image render of the headphones complete with Arnold lighting. The darkened background is reminiscent of a wall, showing the headphones levitating on a blanket of light. I positioned the lights such that the shadows would cut naturally along the contours of the headphones in a pleasing balance between a rigid body and a weightless from. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide168.png "Final Render Completed")


<h1>Week 9: Weeks 1, 2, 3, 4 + 5 + 6 + 7 + 8 + Final Games Modelling</h1>

THE GLOVE: Here is a new scene I am creating, from scratch, a pair of gloves, for the end-of-year games project, Fire Fighter. Inspiration, tutorials, and references for this scene are from Udemy tutorials, YouTube videos, and two books. All sources have been referenced at the end of the page. I started with a standard cube, then selected the scale tool (R) and reduced the cube to a thick rectangle. This will be the polygon starting point for the palm. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide169.png "Began Gloves Modelling")

In the Channel Box / Layout Editor panel, create 4 subdivisions along the Subdivisions Depth box. These will be the index points for the fingers when attached to the palm. Drag individual vertex points to create a rough shape of the hand. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide170.png "Divisions")

Use the rotate tool on individual segments of the four index joints to create a slight curve that resembles the human hand. At this stage simple manipulation will do. Further refinement will come later. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide171.png "Index Joints")

Rotate the object 90 degrees along its horizontal plane (hold J to rotate in increments) so that the back of the palm is visible. Select and delete the back faces of the palm, since this section will join the wrist. Select and shape edges into more of a wrist. Enlarge the portion next to the index finger, where the thumb will be. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide172.png "Wrist Creation")

Hit 3 on the keyboard to smoothen out the shape. The basic structure of the palm is about ready at this stage. The rounded shape is necessary for the structure of a glove. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide173.png "Smoothened Hand")

Extrude the middle finger of the glove out, then create two edge loops to match the number of phalanges on the finger. Since this is a rubber glove, the articulation will be less pronounced than the finger. Select each edge loop and create a varied curve of the finger to imitate the relative stiffness of the glove. Use the move (W) and rotate (E) tool on each edge loop to position to affect the desired shape. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide174.png "Extruded Reference Finger")

Repeat the process, from the previous step, for the index finger. Note that the index finger is typically shorter than the middle finger, and slightly articulated away from the central axis of the hand. In this case I have selected the faces of the index finger and moved it off-centre to create a more realistic model. I have also used the scale tool (R) to reduce the size of the index finger to a more proportional dimension. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide175.png "Index Finger")

The ring finger has been extruded. Like in the previous steps, I will add edge loops, articulate the bends along each loop (phalange) and position the ring finger along a realistic axis to match the rest of the glove. This top view of the glove shows the shape coming along nicely. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide176.png "Ring Finger")

The index, middle, and ring finger have been created, and the little finger is now being shaped. In many ways the little finger requires additional attention, since it is significantly smaller than the other three, and takes its reference from the ring finger. But the process is still the same; just take note of the size. Note also that while this is a glove, it is important to have an idea of the hand and its anatomy underneath, including finger nails, phalanges, wrinkles and axes of movement. In this model I have included the finger nails (which I will later remove) on the fingers to provide additional frames of reference. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide177.png "Little Finger")

The four fingers are complete. The articulation along the phalanges are particularly important for a feeling of reality, because while this is only a glove, when included in a game the object must impute some sense of tactility and grip, which adds to the game experience. Therefore, I have modelled the glove somewhere along the spectrum between an active human hand and a lifeless glove. This sense of movement needs to be conveyed even if animation has not yet been applied. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide178.png "Phalanges Added")

Creating the thumb requires an additional step: the thumb possesses its own knuckle and joint, which protrudes out from below and at an angle to the index finger. In this case I have created that knuckle and joint by creating two edge loops around the entire glove (one for the finger knuckles and the other for the thumb knuckle) then extruded a face from the side of the glove. I then pushed the trailing edges closest to the glove back towards the palm to create the triangular-like protrusion. The thumb will come out from the leading face of the triangle, next to the index finger (highlighted in green, in the image above). ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide179.png "Thumb")

The basic form of the thumb has been created. Further refinement is now required to shape the thumb. Notice the outer plane of the thumb (with the nail) is flatter whereas the inner plane facing the index finger has slight roundedness. I will create this shape in the next step. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide180.png "Thumb Shape")

I have shaped the thumb as described in the step above through a combination of moving, rotating, and scaling individual faces to achieve the desired effect. I have also increased the length of the glove to provide added perspective for the hand, as well as to resemble a standard firefighter’s glove, which tends to be longer and with additional clasps, which I will add in a later step. At this stage, the basic geometry and topology of the glove is complete. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide181.png "Glove Topology")

Up to this stage, the glove connoted more of a dishwashing feel, whereas gloves used by firefighters are much more ergonomically-designed. They are also thicker since the outer glove (pictured here) houses inner layers. To get this heft and ergonomic shape, I selected the faces (pictured above) on either side of the glove, then extruded and rotated them into place, one by one. Experiment with different faces and edges to achieve the desired effect. When modelling in Maya, be prepared to work on method as well as instinct, since no two forms are ever the same, and I have learned that a lot of 3D-modelling involves perception-based decision-making to achieve the best result. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide182.png "Fire Fighter Glove Structure")

I have added further details to the wrist portion of the glove and fingers. By articulating the axis line for each finger along the top of the hand, and adding extension rings around the top phalanges of each finger and the thumb, the glove gets a more definite shape while retaining its rigid form and imputed function for the game. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide183.png "Articulation Lines")

Likewise, the bottom of the glove (palm-facing) follows the form along its planes and edges, to provide a sense of tactility. There is a slight dip in the palm, created using an extrusion and bevel combination with soft selection applied. This dip is another example of imputing, which creates a sense of imagined interactivity with the object during gameplay. The next step will be to apply shaders to the glove. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide184.png "Palm Shaping")

I have applied a combination of shaders and texture materials, also available on Substance Painter, to different parts of the glove. The black wrist band has a shiny, metallic shader applied, while the orange support bands have less specular roll-off to make the wrist band stand out. The rest of the glove has a rubbery blinn applied, while the articulations on the fingers have a more reflective shader to contrast with the rest of the skin. The colours were specifically chosen to evoke the traditional firefighter’s uniform, but with a bumped up contrast to appeal to the younger demographic. Finally, the thumb has been manipulated to resemble a hydrant to further evoke connotations that align with gameplay. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide185.png "Shaders")

This is the final render of the top of the glove using Arnold. For gameplay, I will preserve a more cartoon-driven look since the game is directed at a more playful demographic and expectation. Creating this glove was a great experience and lead-in to modelling the human anatomy. I will also be creating a version of this glove for the left hand, which will be used to press the buttons and controls in the game. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide186.png "Top Right Hand Glove Final Render")

This is the final render of the bottom of the glove, using Arnold. I have rendered both, the top and bottom of the glove in two separate scenes for reference, and further comparison and analysis during gameplay. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide187.png "Bottom Right Hand Glove Final Render")

Here is the left glove, modelled in a pointing pose, to press the necessary buttons in the game. I considered mirroring / flipping the right glove, but the authenticity of the pose was insufficient. As a result, I modelled this hand from scratch as well, using the steps listed for the previous glove. I was able to achieve the bent fingers and folded thumb by creating a basic set of polygons, then extruding and adjusting the faces to achieve the desired angle. I have also shaded this glove to match the other, but with slight differences in the shading sections, to create greater distinction between the two hands since both are equally necessary but perform completely separate actions, which, I anticipate, will help gameplay. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide188.png "Left Hand Glove Final Render")


<h1>Weeks 10 and Beyond: Weeks 1, 2, 3, 4 + 5 + 6 + 7 + 8 + 9 + Continued Final Games Modelling</h1>

THE FANCY HEADSTONE: Here is a new scene I am creating, from scratch, a tombstone, for the end-of-year games project, Fire Fighter, in which this flammable tombstone will add some levity and interest to the game. All sources have been referenced at the end of the page. Start by creating a simple cube and shaping it into a rectangular cuboid, using the scale tool (R). Ensure that there is space in front of the cube for the grave or other embellishments. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide189.png "Headstone")

Here is the basic shape of the head stone. To get the rounded top that is characteristic of most head stones, select the short edges on the top face, then apply a bevel to these two edges. Adjust the number of segments till the desired rounded top shape is achieved. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide190.png "Rounded Tops")

Here is the basic shape of the head stone, with the bevel applied. Next step is to create some unevenness along the edges of the head stone to add the feeling of age and wear and tear. This can be achieved by manipulating the individual vertices along the edges of the object. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide191.png "Basic Shape")

In this example, I have bevelled the leading edge of the head stone, then extruded the face slightly forward to create an additional ring. I then extruded that ring and adjusted the edges individual to create this shape. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide192.png "Extruded Name Plate")

Further refinement has been added to the tomb stone. I created edge loops along the top edge of the head stone, then extruded a cross-shaped surface above the plane. The protruding indentation on the front of the head stone was created by selecting the face of the head stone, then merging its vertices to the centre, by using the Merge to Center command. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide193.png "Cross Feature")

Additional detailing has been carried out around the raised cross-emblem. I sub-divided the faces around the cross, then creased the edges to create a radiance effect – like the rays of the sun emanating from the top of the head stone. The bottom has been cut in the shape of a triangle. Together the face of the head stone resembles a face (with eyes and a mouth) yet retains its overall structure and identity. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide194.png "Resting Area")

I have added some text for the customary R.I.P. lettering and created another cross at the top of the head stone to provide a more elaborate style. I then bridged two faces to create the arch over the top cross for added emphasis. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide195.png "Lettering")

I have added a spire to the top of the head stone, which adds greater emphasis and noticeability when integrated into the game. As these items will be on fire, it is important to provide extraneous detail to make these objects more recognisable in a shorter time. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide196.png "Spire")

The top of the head stone has been shaped to resemble a mitre, evoking a more graveyard scene. The extrusions on the sides are a result of bridging faces from either side of the crown on the head stone, then shaping them into protrusions. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide197.png "Mitre")

All modelling has been completed, using a number of tools described in this document. The next stage is to set hypershading and a UV map to the head stone. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide198.png "Model Headstone")

This is the hypershading window, which can be accessed from Window > Rendering Editors > Hypershade. In this window a number of different hypershaders can be selected and modified as required to create new, hybrid hypershaders for the objects in the scene. Note that once a hypershader has been created, click and drag the hypershader node into the top hypershader panel using the middle mouse button. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide199.png "Hypershading")

In this example, I have chosen the SolidFractal option and altered the colour, ratio, and grain numbers sliders to achieve the dark and stone-worn look for the headstone. I then created a granite hypershader for the lettering, in a lighter shade, and applied both hypershaders to their respective objects in the scene. To assign the hypershader to the object, click and drag the hypershader, from the hypershader panel, onto the object using the middle mouse button. Note that the hypershader does not replace the shader (e.g. lambert) currently applied, but links to it. This link can be accessed by clicking the black arrow next to the shader, in order to adjust the hypershader’s properties and values. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide200.png "Solid Fractals")

The hypershaders have been applied to the head stone and lettering. Note that when a hypershader is applied, a control box appears, which can be manipulated using the W, E, and R keys to control the hypershader distribution, position, and scale as it wraps around the object. Play with this control to further optimise the hypershading on the object. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide201.png "Hypershader Distribution")

In this example I have rescaled the hypershader to give the head stone a more finite look and feel, which should work better during gameplay. It is also a good idea to keep rendering out the result in the render window (in low resolution) to ensure the final product will as closely resemble what the scene is currently showing. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide202.png "Optimised Hypershader")

While this object will be used within Unreal Engine, I am still testing to see how the head stone looks under similar lighting conditions, using Arnold area lighting, atmospheric volume, which catches the area lights, and Maya’s in-built directional lighting to create the proper mood. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide203.png "Optimised Lighting")

I am preparing the head stone for the final render as an image, for the purposes of documentation and follow-up. In this example I will be using both Maya Software 2.0 for quick rendering, and Arnold for a longer but higher quality render. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide204.png "Preparing for Render")

This is the final render of the head stone in Maya. The look and feel work well and I will be importing this as an asset into Unreal Engine, to test its feasibility as a game-play object. The over result is quite pleasing and will (hopefully) look good enough that when set on fire will compel the player to extinguish the blaze as quickly as possible. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide205.png "Final Headstone Render")

Using a similar workflow and process, I also modelled this electric SUV, which will be part of the game. The modelling process requires a method, which once understood can be applied to any project framework. I will be using similar processes described here, as well as the software (Maya, Substance, and UE4) to build out, model, and integrate the elements required for the final game. ![alt tag](https://github.com/arjunkhara/3D-Modelling-Repo/blob/master/images-weeks-6-10/Slide206.png "Completed SUV Car Model")

This is a model of the chair that is on fire in the game. The chair, like the other objects, has been modelled using Maya and textured in Substance Painter and re-built in Unreal Engine 4 to fit into the Tron-like environment of the game. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/image-assets/Chair.jpg "Chair Model")

This is a model of the barbeque stove that is on fire in the game. The barbeque stove has been modelled using Maya and textured in Substance Painter and re-built in Unreal Engine 4 to fit into the Tron-like environment of the game. The stove also contains a gas canister, which implies to the player the need for a gas-suppressant. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/image-assets/BBQ-Stove.jpg "Barbecue Stove Model")

This is a model of the paint can that is on fire in the game. The paint can has been modelled using Maya and textured in Substance Painter. Given the size of the paint can, no re-builds were required in Unreal Engine 4. The paint can was deliberately textured and UV-mapped to hint at the Tron-like fire environment, following the same colour palette I picked for the game. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/image-assets/Paint-Can.jpg "Paint Can Model")

This is a model of the earphones that are on fire in the game. The earphones have been modelled using Maya and textured in Substance Painter, then re-materialised in Unreal Engine 4 to provide the Tron-like laser outline around the ear muffs for added effect. The proces of creating the earphones from scratch has been detailed already in an earlier section of this document. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/image-assets/Headphones.PNG "Earphones Model")

This is the splash screen that welcomes players when they first launch and open the FireFighter game. The image of the original firefighter glove I modelled, has been used here, together with a flame burning from the palm and creating slight melting around the hottest areas. When a player clicks on the screen, gameplay begins. Note that this splash screen is animated in the game, so the fire flickers, inviting the player to click and interact with the splash screen in an intuitive manner. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/image-assets/Fire-Fighter-Splash.jpg "Game Splash Screen")



___

<h1>DOCUMENTING GAMES-BUILDING PROGRESS IN UNREAL ENGINE</h1>

Hello. I’m Arjun Khara, a student at Goldsmiths College, University of London. This is my introduction to Unreal Engine. As this is my first time using any games-engine software, I will be documenting all my learnings with Unreal Engine (UE) for the purposes of the module, as well as to provide a rudimentary introduction to future students of this module who, like me, have no experience with game engines but want to learn as much and as quickly as possible.
___

<h2>Unreal Engine and Blueprints: Section 1</h2>

This is the welcome screen in Unreal Engine. Development will initially be done through Blueprints, UE’s visual coding environment, like Scratch. Click on the Blank option (first option, top-left). Also ensure that the ‘With Starter Content’ option is selected, from the bottom three boxes, below the menu. Note, the ‘With Starter Content’ option box does not light up like the options above. The wording instead toggles between ‘With Starter Content’ and ‘No Starter Content’. Click on Create Project. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide1.PNG "Opening and using Unreal Engine")

After clicking ‘Create Project’ this is the screen that appears. This is a barebones environment for development, and further assets for the game, such as characters, fireballs, structures etc. will be initially imported from UE’s wiki repository. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide2.PNG "First Unreal Project")

Organisation is important at the outset itself. Double-click the ‘Starter Content’ folder to reveal the additional folder options. Notice that the folders are arranged in alphabetical order. Right click in the grey area and create a new folder. Label this folder ‘Character’. All character assets will go into this folder. Alternatively, a separate character folder can be created outside the Starter Content folder. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide3.PNG "Organising Folders and Assets")

Once the folders have been setup, open a web browser and navigate to the following URL: https://wiki.unrealengine.com/File:ThirdPerson_FBX.zip and download the zip file. This file contains all the beginners’ assets that will be used in the UE project. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints-screenshots/unreal-blueprints-images-folder/Slide4.PNG "Accessing UE FBX Assets")

Once downloaded and extracted (unzipped) the folder will contain the following assets which will need importing into UE. Ensure, before importing, that the SK_Mannequin asset is included in the list of items. This will be the main character to build, manipulate, and have perform actions within the game environment. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide5.PNG "Unzipping and Installing FBX Assets")

In UE, click on ‘Import’ (in the bottom panel above the folders) and import the SK_Mannequin asset. UE will import the file and open an FBX Import Options dialog box. All options, save for one, can be left to the default. Under the ‘Mesh’ panel, beneath where the ‘Skeleton’ options are, is a small, white arrow. Click this arrow once to reveal the advanced options, and change the ‘Normal Import Method’ dropdown menu from ‘Compute Normals’ to ‘Import Normals’. This is to ensure a smoother character mesh. Click on ‘Import’ at the bottom of the panel, and ignore any warning screens that may pop up. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide6.PNG "Importing Assets and Viewing Advanced Options")

This is the screen with the additional options that now displays. The skeleton mesh has been added together with a Physics Asset and an SK Mannequin Skeleton for multiple use when building more than one character. There are also some materials (skins) that are applied to the skeleton mesh. These material options are the spheres displayed in the panel. Double-click on the SK_Mannequin asset (with the pink bar) to view the asset and its properties. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide7.PNG "Accessing Materials Options")

This is the persona window. Hold down Alt and drag along the view screen to see the camera pan across perspectives. Toggle between the ‘mesh’ and ‘Skeleton’ views by choosing the corresponding option from the top right boxes. Each selection opens a new tab, like a browser interface, and reveals the properties for that selection. After exploring these options, close these tabs to return to the main UE screen. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide8.PNG "Mannequins and Personas")

At the main UE screen, create another folder called ‘Animations’ and import all of the remaining FBX assets into this new folder. In the ‘Import Options’ dialog box, there is an option for Skeleton in the drop-down menu. Click on the drop-down menu and choose the skeleton mannequin that was previous imported. This will link the animations to that skeleton mesh. Leave the other options to their default values and click on ‘Import All’. Ignore any warnings that might come up. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide9.PNG "Skeleton Mesh")

Once the import is completed, click on the ‘Save All’ button to save all the assets that have been imported. (Any asset with an asterisk sign indicates that asset has yet to be saved). In the ‘Save All’ dialog box, there is a list of assets with a checkbox next to each, providing an option to save all assets or only the ones selected with a check mark. Click on ‘Save All’ to save all the imported assets. Notice the asterisks have disappeared, indicating all assets have been saved. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide10.PNG "Saving Progress")

Persona is UE’s animation editor. It provides animation details and controls over the different animation states. From the Animations folder, double-click on the ‘ThirdPersonIdle’ asset to enter the animation screen and properties panel. The timeline running below shows how the character animates across a specific duration. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide11.PNG "Third person idle state")

The skeleton tree (left pane) contains the entire skeleton hierarchy of the character. Click on any of the joints or sections to highlight that part on the skeleton. Right-clicking on any joint or section and selecting ‘Add Socket’ allows the user to insert an additional holder to place something inside, such as a stick or a weapon. A socket is essentially a placeholder for further assets to sit within. These assets can be added in Blueprints. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide12.PNG "Socket Installation")

Toggling between W, E, and R allow the socket to be moved, rotated, and scaled for fine positioning and detailing of the additional asset. Likewise, any existing part of the skeleton can be moved, rotated, and scaled to change the anatomy of the character. Use the middle mouse button to zoom into and out of the skeleton. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide13.PNG "Manipulating Skeleton State")

The options at the top of view screen, ‘Perspective’, ‘Detail Lighting’, ‘Show’, and ‘LOD Auto’, provide additional options to understand the character. These options help to navigate around the character and add or remove information about the character. For example, the ‘Perspective’ option is used to change how the character is viewed, i.e. from the top, left, right, bottom etc. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide14.PNG "Changing Perspective")

Within the Mesh tab (top right) additional information on clothing, skinning, materials etc is available. Each tab contains its own specific options that correspond to the character, depending on what controls are required over which types of assets, i.e. animation, appearance, anatomy etc. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide15.PNG "Mesh Tab Information")

Within the animations tab at the bottom, there is an Asset Browser that lists all the animations the character can perform. Double-clicking on each, changes the animation on screen and the character begins performing that particular action. To go back to the initial state, click on the back, white arrow. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide16.PNG "Navigating Between Assets")

To setup input settings to control the character, navigate to the main UE screen, then go to Edit > Project Settings. Under the Engine list, there is a link called ‘Input’. Click on the ‘Input’ link, then navigate to the Bindings panel. Click on ‘Axis Mappings’ then open the drop-down arrow that appears. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide17.PNG "Binding Panels")

Rename the Axis Mapping created, from the previous step, to MoveForward and press enter. A new set of drop-downs for controls is generated. Hit the W key to bring up the basic W command key. The W key has now been assigned to forward movement. For reverse movement, create a new drop-down option by clicking the plus symbol, then assign the S key. To make the character move backwards when S is pressed, change the scale value (to the side) to -1.0. Likewise, go ahead and assign the up cursor key and down cursor key to move forward and backward (by changing the scale for the down cursor key to -1.0). ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide18.PNG "Moving Forward and Backward")

Likewise, for left and right movement, create a new Axis Mappings, name this MoveRight, and press enter. Create three sub drop-downs, as in the previous step. Assign the D and right cursor key to move right, and the A and left cursor key to move left. Remember to change the scale to -1.0 for the A and left cursor keys. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide19.PNG "Moving Left and Right")

For jumping and punching actions, create new Action Mappings. Note that Axis Mappings provide movement and navigation controls, whereas Action Mappings provide action controls for the character, such as jumping, punching, kicking etc. In this example, the spacebar has been assigned to the jump action, and the left mouse button has been assigned to the punch button. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide20.PNG "Actions and Axis Mapping")

To give a character a new skin or material, right-click in the grey box area then choose the Material option. A new asset box is created next to the spheres. Give it a new, meaningful name that is easy to reference. Double-click the new material instance to open its properties. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide21.PNG "Referencing Materials")

This is the materials editor screen. Right-click on the grid to bring up the context menu, then choose Vectors Parameters. UE will setup a new node with RGB and alpha parameters. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide22.PNG "Vector Parameters")

In the Details panel on the left, rename the parameter to something meaningful. Then navigate to the Material Expression Vector Parameter and choose a colour from the colour picker, in this case a medium red. The Vector Parameter node will now have the new name on the top of its window, and the colour that was picked. If this colour is not showing, make sure that the ‘Live Preview’ box in the top menu bar is selected. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide23.PNG "Colour Pickers")

Dragging a line from the white pin (top) of the base colour node to the Basic Colour pin in the CharacterMaterial panel will update the colour of the material currently assigned to the character. This change is shown in the preview window to the left, where the sphere takes on the new colour. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide24.PNG "Mapping Materials in Blueprints")

To break a link between the nodes, right click on the pin with the joining line and select Break Link(s). This will be particularly useful when working later with Blueprints. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide25.PNG "Breaking Blueprints Connections")

In this example, several properties have been used: BaseColour; Fresnel; Power; Lerp; Scalar (Metallic); and Scalar (Roughness). Note the positions of the joins from the pins. These joins tell the story of how the final material has been created, outputted in the preview window on the left. Note also how the material builds itself from the BaseColour panel to the final Character Material panel. When the result is satisfactory, click on ‘Apply’ then ‘Save’ from the top icon menu bar. Then close the materials panel. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide26.PNG "Adding Additional Features with Blueprints")

Once the new material has been created, right click the asset then select ‘Create Character Material’. A new asset is created, called ‘CharacterMaterialInstance’. Double-clicking on this new asset brings up the properties panel. This is useful since the properties of the material can be adjusted independently for different characters and objects without going through the process of recreating a new material asset from scratch. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide27.PNG "Instance of Material")

To assign the new character material to the character, double click the character asset box (SK_Mannequin), then tear off the tab so that both the Mesh view as well as the main UE view are visible. Then drag the new material asset from the UE window onto the Material Slots icon (the existing material image). The character is reskinned with the new material. When the result is satisfactory, click the ‘Save’ icon at the top left of the SK_Mannequin window. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide28.PNG "Final Character Materials Map Done")

<h2>Unreal Engine and Blueprints: Section 2</h2>

Trigger Lighting: In this scene I am creating a trigger area with lighting, which turns on and off as a player enters a specific area. All the actions in this scene are controlled entirely in Blueprints. Since most of this project focuses on familiarity with Blueprints, it is important to know how to navigate to and around this section. In any project window, there is a toolbar at the top with Blueprints as one of the options. Click on Blueprints > Open Level Blueprint to access these controls. Note that in Blueprints, events have a red bar, while functions have a blue bar. This is one way of immediately differentiating between blocks. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide29.PNG "Navigating Blueprints Further")

Start by creating a point light. Click on the pane to the left of the screen, scroll down to Lights, then click and drag a point light onto the scene. The movement (W), rotation (E) and scale (R) can all be manipulated using the defined keyboard shortcuts. Move the light into position. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide30.PNG "Positioning the Light")

Once the light is on the scene, go back to the Blueprints window opened earlier, and right click on the grid. From the pop-up menu, choose the ‘Create a Reference to Point Light’ option. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide31.PNG "Referencing Light Assets")

Notice that a new node for the point light has been created. From this node, a number of connections can be run to other assets to create relationships necessary for the game. An event now has to be created for these relationships to work. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide32.PNG "Positioning the Light")

For ease of reference, it is a good idea to have the two windows side by side. This may be difficult on a smaller screen, but is immensely helpful when developing a game with several Blueprints and references, as I expect to soon enough. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide33.PNG "Side by Side Panels")

Navigate back to the left pane, scroll to Volumes, and choose ‘Trigger Volume’ from the list. Drag this trigger volume box onto the scene. Then right click in the Blueprints window and choose Add Event for Trigger Volume 1 > Collision > Add on Actor Begin Overlap ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide34.PNG "Collision Event")

Notice that a new red node, titled OnActorBeginOverlap (TriggerVolume) has been created in the Blueprint window. This node is an event node; it also has pins which can be connected to the blue lightbulb node (the object node) to establish a relationship. Note also that the pins are colour-coded, which will be useful. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide35.PNG "Red Nodes")

Click on the blue pin of the Point Light and drag out a connector line. From the dialog box that pops up, type ‘visibility’ into the search bar, then click on Toggle Visibility. Two new nodes are created with connector links between them automatically set up. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide36.PNG "Connected Light to Event")

I have enlarged the Blueprint window here for easier reference and neatened the layout. Notice that the pins are colour and shape-coded, which makes for easy referencing between how each node’s pins connect to the others. In this case, the red event node, titled (OnActoBeginOverlap) has a white triangular pin, as does the blue function node, titled Toggle Visibility. Drag a connector (execute command) from the red node to the blue node. A relationship has now been created. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide37.PNG "Complete Blueprint of Trigger and Actor Overlap")

Navigate to the main scene window and press the Play button, located at the top of the window. Using the mouse and direction keys on the keyboard, move around the scene. Notice that when the player enters the light area, the light turns on. When the player exits and re-enters the light area, the light turns off. This is the toggle action that has been setup in Blueprints so far. To exit from the live scene and back into editing mode, hit Esc. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide38.PNG "Final Scene Created")

<h2>Unreal Engine and Blueprints: Section 3</h2>

Sliding Doors: In this example I am recreating a scene from scratch, which I learned from YouTube (Virtus Learning Hub). When the player approaches a door, the two glass panes slide away from each other, a light turns on and a sound plays. To create a sliding door, the object of the door has to first be created. In a new project, click on the arrow next to Content, then choose Props > Glass Window. Click and drag the glass window onto the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide39.PNG "Starter Content Assets")

The glass door has been created and is in the scene. The Contents folder has a sub-folder inside titled StarterContent. This is a useful repository of basic items that are found most often in games, and can be used to quickly mock up or prototype a game in Unreal Engine. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide40.PNG "Glass Door")

With the glass window selected, copy-paste the object  (Ctrl + C, then Ctrl + V) to create two glass windows. Together these will act as the glass doors that will slide open and close when an event is triggered. Before that, though, a pivot point needs to be set for the right door, from where the sliding action takes place. Otherwise both doors will slide open in the same direction instead of away from each other. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide41.PNG "Scene Created")

Right click the door, then choose Transform > Mirror Y (to flip it along the Y-axis). The right glass window / door flips over and the two pivot points (one for each door) are now at the far edges and in position. Remember to drag the right door away from the left, since mirroring along the Y-axis will create a perfect overlap with the other door. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide42.PNG "Mirroring")

Both the doors are now in position and ready for further actions. With the basic setup done, additional elements like lighting and door frames can be added from the Content > StarterContent folders. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide43.PNG "Setting Pivot Point")

In this example, I have created a door frame and added a point light. The point light and the sliding doors will be animated using Blueprints. The door frame adds a level of reference and perception to this example. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide44.PNG "Door Frame and Point Light")

The lightbulb intensity has been set to zero, and the colour has been changed to red. These settings can be accessed in the panel on the right, which activates when the object, in this case the lightbulb, has been clicked on. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide45.PNG "Light Intensity")

I am also adding a sound that will be played when the doors open. To access the sounds library, navigate to StarterContent > Audio, then drag an audio file onto the scene. In this example I am going to add the default Starter Music Cue. In the audio panel (which pops up when the audio element is selected) scroll to the Activation section and ensure that Auto Activate is deselected, so that the sound does not start playing as soon as the scene begins, but only when the door opens. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide46.PNG "Sound Asset")

This is the scene all ready and set for Blueprint controls. Add anything else that may make the scene more game-like. For this example, I am going to stick to the sliding doors, lightbulb and audio, as per the tutorial. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide47.PNG "Scene Setup")

Select one of the doors, then go to Cinematics > Add Matinee (Legacy) for the sake of the tutorial. A layers and play-head screen will open. This is where groups can be created, which will then be acted on together in Blueprints. Right click in the darker grey space to the left and select Add Empty Group. Give it an identifying label such as LeftDoor then press enter. Make sure that the door has been selected in the scene before creating the new empty group. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide48.PNG "Setting up Matinee")

Once the layer has been created, a bar will appear across the play area with the name given in the previous step. Right click on the layer and choose Add New Movement Track. Then drag the time bars out or in (at either ends of the frames play area) using the red triangle at the bottom of the extreme right-side bar (hold Alt and move the mouse to zoom out so that the entire timeline fits in the window), to set a duration for the door to move. In this example I have set it to 2 seconds. Once done, press enter to create a new keyframe. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide49.PNG "Amending Time Layers")

The duration of the door’s movement has been set to 2 seconds (from the previous step) and is shown by the green shaded area in the frames play area, bound by the two white lines. Pressing enter, once the duration has been set will create a keyframe at the beginning of the play-head. This keyframe looks like a red triangle. Hold down Ctrl and drag this red triangle out to where the end time bar has been set (in this case 2 seconds). Once done, navigate to the scene, and drag the door using the move command (W) to its open position. Press the Play button at the top of the Matinee window to watch the animation. The door slides open. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide50.PNG "Keyframes for Left Door")

Repeat the process for the RightDoor then press Play in the Matinee window. Now both doors slide away from each other. This is the basic setup for moving the doors. Other properties, such as intensity, transparency, rotation, colour, volume etc. can also be set using keyframes, as demonstrated in the next step, using lighting and sound. This interface is very familiar to users of Adobe AfterEffects or ScreenFlow. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide51.PNG "Keyframes for Right Door")

In this example, I have created a New Lighting Group (instead of new empty group) then made two keyframes for the lighting, one for the off state (at the beginning) and one for the on state (at the end). I have set the intensity to 5000 at the end, so that when the doors open, the light is on and bright. The intensity settings (as well as all the other light properties) can be adjusted from the scene window, on the right pane. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide52.PNG "Lighting Empty Group")

The final step is to add sound. Create a New Empty Group and give it the name SoundDoors, then right click and instead of choosing the usual movement track, choose Add New Sound Track. A new sound layer is created below the Sound Empty Group. Once again, ensure that the object is selected in the scene before creating these layers, otherwise it will not work. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide53.PNG "Sound Empty Group")

With the sound layers created, click on the white start time bar, and hit enter to create a new keyframe. The name of the audio file, in this case, Starter_Music_Cue, appears on the green bar. Press Play at the top of the Matinee Window and watch the scene. The doors slide open, the light comes on, and the sound plays. The next step is to setup Blueprints with delays. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide54.PNG "Keyframing Sound Group")

To trigger the matinee event, use a box trigger. Navigate to the left pane and select Basic > Box Trigger. Then drag the box trigger over to the scene and place it in front of the door. This will be the trigger for a player to activate, which will cause the matinee to play. Scale up the trigger area if needed so that the interaction area is large enough to catch any event. Instead of a box trigger, a trigger volume (from the previous notes) can also be used. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide55.PNG "Box Trigger Added")

A trigger volume node has been created in the Blueprints window. This trigger event can now be linked to the Matinee event. The trigger volume node is an event node (red) that needs to be connected to a function node (blue) via the corresponding pins, in this case white to white. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide56.PNG "Trigger Volume Node Added to Blueprints")

Make sure that in the scene panel the Matinee icon (a film clapper) is selected. Once done, return to the Blueprints window, right click then type Play in the search bar. Choose the Play function, which will create a Play node in the Blueprints window. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide57.PNG "Matinee Node Added to Blueprints")

The Play function for the Matinee has been created. To link the player movements to the matinee playback, simply link up the white pin on the Trigger Volume event node (in red) to the white pin on the Play function node (in blue). Once done, return to the scene window and click Play. When the player (camera first person) passes through the trigger area, the matinee plays – the doors slide open, the light shines and the sound turns on. However, the doors do not close after the event. To fix this, a delay needs to be added. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide58.PNG "Play Function Added to Matinee")

Right click in the Blueprints window, then type Delay. A Delay function is created. Link the Delay node to the Play node using the corresponding white pins. A Delay function can also take a duration value, i.e. the duration of the delay, or how long the action is held for before playing in reverse. This Delay function will then be connected to a Reverse function for the Matinee. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide59.PNG "Delay Function")

Ensure that the Matinee icon (film clapper) is selected in the scene. In the Blueprints window, right click and type ‘Reverse’ in the search bar. Ensure that the Reverse function under the Cinematic tab is selected. Link white pin in the Delay function node to the white pin in the Reverse node. Click on the Compile button at the top left of the main Blueprints window. The Blueprint is now complete. Return to the scene and press Play. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide60.PNG "Reverse Function")

This is the final scene, built entirely from Blueprints and the Matinee. In newer versions of Unreal Engine, the Matinee has been relegated to legacy mode, and replaced by Cinematics. However, the Matinee still works and can be used with Blueprints as shown in this example. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide61.PNG "Final Result")
Reference made to tutorials of 'Unreal Engine' (https://www.youtube.com/watch?v=EFXMW_UEDco&list=PLZlv_N0_O1gY35ezlSQn1sWOGfh4C7ewO), 'Matthew Palaje' (https://www.youtube.com/watch?v=Wd2IFU0okrE), Sparckman (https://www.youtube.com/watch?v=0AsFmYpTG48), and Virtus Learning Hub (https://www.youtube.com/watch?v=LuqmeOi4_Ag).

<h2>Unreal Engine and Blueprints: Section 4</h2>

In this example, I have created the fire effect by going to StarterContent > Blueprints > Blueprints_Effect_Fire and dragged the instance of this fire onto the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide62.PNG "Fire Creation")

Double-click the Blueprints_Effects_Fire icon to enter the Blueprints for the fire effect. Then click on Viewport to enter the component mode of the fire effect. In this section I will change the effect of the fire’s interaction with the player. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide63.PNG "Component Manipulation")

Navigate to the Add Component button on the left pane, and add a Post Process component. Under the Colour Grading > White Balance > Global > Saturation settings, change the colour of the fire to the necessary tones required for the game, in this case red fire for water suppressant, blue fire for powder suppressant, and green fire for carbon dioxide suppressant. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide64.PNG "Fire Colour Settings")

Here I have created the red fire necessary for items which will require a water suppressant to put out the flames. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide65.PNG "Red Fire Instance")

Here I have created the blue fire necessary for items which will require a powder suppressant to put out the flames. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide66.PNG "Blue Fire Instance")

Here I have created the green fire necessary for items which will require a carbon dioxide suppressant to put out the flames. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide67.PNG "Green Fire Instance")

When the character gets hit by the flaming object the character takes on damage. This procedure has been built and integrated into the Blueprints of our game build. Note the use of Cast ToFirstPersonCharacter node and Apply Damage node function. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide68.PNG "Damage Application for Character")

Because this is a fire fighter game, and the main projectile source is a hose, the fire rate has to be constant when the mouse button (or appropriate trigger) is pressed and held, unlike a shotgun which works as a single press, single projectile release. I have used Blueprints here to reconfigure the fire rate of the first-person character in our game. The nodes in use are InputAction Fire; Sequence; Gate; Sequence; Montage Play; Retriggerable Delay. I then lowered the value of the duration in the Retriggerable Delay node to make the projectiles go faster, or stream, as is the case in hoses. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide69.PNG "Fire Rate")

The effect is clear to see and the spray of pellets works well. In the next steps following this Blueprint, I will convert the pellets to a more watery, and gassy substance to give the suppressant materials a more realistic look and feel. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide70.PNG "Fire Rate Demo")

In this example, I am using Blueprints to increase the explosive quality of the projectile on impact, as is the case when using a powder suppressant, where the material spreads and disseminates on impact with the object. I am altering the MyProjectile Blueprints, and have added a Radial Force, then increased the Impulse Strength in the right pane. I have also increased the destructible damage to little over 1, and the Radius Force to little over 230. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide71.PNG "Projectile Explosion")

Back in the event graph, remove the node for DestroyActor, and create a new Sphere > Get. Then link the Sphere node to a new function node, titled DestroyComponent. This is to prepare for the next step where the objects get destroyed but the particle and sound assets remain in place for a while longer. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide72.PNG "Object Destruction")

Create a new Radial Force > Get node, then drag out a connection from its pin and create a Fire Impulse function node. The Fire Impulse node will ensure that the destruction effects linger after the object has been destroyed. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide73.PNG "Fire Impulse Lingers")

However, the Fire Impulse node will keep playing the destruction effects back, and so I have created a Do Once node to make sure the Fire Impulse only occurs once per instance of destruction. Link the DestroyComponent function node to the DoOnce node, then link the Completed pin on the DoOnce node to the FireImpulse node to force the FireImpulse function to perform just one instance of destruction. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide74.PNG "Single Instance of Destruction")

Once that relationship has been setup, drag out a connector from the pin of the FireImpulse function node and create a new function called Spawn Emitter at Location. From the Emitter Template choose the desired effect. I have chosen the Explosion effect template for testing, but will ultimately choose the steam effect, which is what happens when an object on fire is doused. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide75.PNG "Spawn Emitter Location")

Because the location of the emitter matters, re-drag a connector from the radial force pin and create a GetWorldLocation node. Then link the Return pin on the GetWorldLocation node to the Location pin on the Spawn Emitter at Location node. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide76.PNG "World Location")

From the white pin on the Spawn Emitter at Location, drag out a new connector and create the Spawn Sound Attached node. Then choose Explosion01 from the Sound Template dropdown menu within the SpawnSoundAttached node. Then connect the Return Value pin on the SpawnEmitteratLocation node to the Attach to Component pin on the SpawnSoundAttached node. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide77.PNG "Sound Emitter")

Finally, drag out a connector form the SpawnSoundAttached node and create a delay node and set the duration to 2. Then drag out the a connector from the Completed pin on the Delay node to create the DestroyActor node. Compile the Blueprint and play the game in the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide78.PNG "Actor Destruction")

I have altered the sound effects to a hissing steam sound, rather than an explosion, and changed the visual output to vapour rising, which fits perfectly with the theme of the game. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide79.PNG "Sound Effect Altered")

This Blueprint record shows the changes, with respect to the output above, as well as the entire flow of logic for this process. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide80.PNG "Final Blueprint for Game Douse Effects")


<h2>Unreal Engine and Blueprints: Section 5</h2>

Day and Night Cycles in Unreal Engine 4 With Blueprints: In this example I will be learning how to use Blueprints to change the default noon-day static lighting to a continuously looping day-night cycle, complete with sunrises, sunsets, and dark starry skies. In the World Outliner pane (on the right) type in Light Source Directional to locate the asset. Then scroll down to the properties panel > Transform > Mobility, and change the mobility to moveable. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide81.PNG "Day Night Cycle Started")

Once the light source has been set to moveable, open the Level Blueprints, then right-click and type timeline. Click on the Add Timeline to create a Timeline_0 node. This is the node that will rove the light across the sky over the timeline, creating the day and night cycle. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide82.PNG "Day Moveable Light Source")

The timeline node has been added to the Blueprint. Double-click on the node to access the timeline template properties. Modifications are required in this section to control to the duration and loop of the timeline. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide83.PNG "Timeline Node Added")

In the timeline template view (after double-clicking the node) change the Length value from 5 seconds (default) to 24 seconds. Therefore each second will represent an hour in the game. Then check the boxes for AutoPlay and Loop. This is to ensure the day and night cycle are automatic and keep looping forever. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide84.PNG "Duration and Loops")

Once the parameters for the Length, AutoPlay, and Loop are set, click on the F (function) button to create a float track. In the name box, enter a name for the float track. This float track will control the position of the moveable light source. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide85.PNG "Float Track Added")

Create a new keyframe by clicking and pressing shift together. In the Time box, enter 0, and in the Value box, enter 0. These settings signify the start of the day. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide86.PNG "Sunrise Values")

Create another keyframe (click + shift) and in the Time box enter 24, and in the Value box, enter 360. These settings for this keyframe signify the end of the day-night cycle. Note that the value box contains the angle of sweep for the light source as it curves around and under the scene, like the sun and the earth. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide87.PNG "Sunset Values")

Press the ‘Horizontal Zoom’ and ‘Vertical Zoom’ buttons at the top left of the graph shows the linear relationship that has been created. Once this is done, return to Blueprints by closing the timeline template box tab. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide88.PNG "Linear Relationship Graph")

Keeping both windows open (Level Blueprints and Scene Editor) drag in the Light Source asset into the Blueprints window to create the Light Source node. Note that at this stage the motion of the light source (as per the timeline template) is linear. To make the light source rotate around the scene, a rotation node is required. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide89.PNG "Light Source Node")

Right-click in the Blueprints window and type ‘Make Rotator’ to create the corresponding node. Then link the Y Pitch pin in the ‘Make Rotator’ node to the Position pin in the ‘Timeline_0’ node. This will cause the linear relationship to take on degree rotation. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide90.PNG "Rotator Node")

Drag a connector from the blue pin on the Light Source node, and create a ‘SetActorRotation’ function node. This function node will control the rotation. From the ‘Make Rotator’ node, drag a connector from the Return Value pin and connect it to the New Rotation pin on the ‘SetActorRotation’ node. Next, drag a connector from the Update pin in the ‘Timeline_0’ node and connect it to the white pin of the ‘SetActorRotation’ node. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide91.PNG "Set Actor Rotation Function Node")

Navigate back to the scene window, and from the World Outliner, type in skysphere. Then drag the asset into the Blueprints window to create the SkySphereBlueprint node. This node represents the sun point-light in the sky, for the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide92.PNG "Sky Sphere Node")

From the ‘SkySphereBlueprint’ node, drag a connector off the blue pin and type ‘Update Sun Direction’ to create the corresponding node. This node controls the direction of the sun’s light as it moves over the scene. Drag a connector from the white pin of the ‘Set Actor Rotation’ node and link it to the white pin on the ‘Update Sun Direction’ node. Now the rotation and the sunlight direction are linked, so when the sun rotates the light direction changes accordingly. The Blueprint is ready. Click on Compile, then return to the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide93.PNG "Light Direction")

In the scene editor window, click on Build > Build Lighting Only to rebuild the lighting and link up the new assets within this scene. The lighting has to re-built to reflect the most up-to-date settings for the lighting assets (worked on in Blueprints) otherwise the scene will default to the current lighting state and the changes will not be played out in the scene during simulation. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide94.PNG "Rebuilding Lighting")

A message at the bottom right of the screen will provide information on far along the build for the lighting has progressed. Once the build is complete, press the play button from the icon menu above to simulate the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide95.PNG "Lighting Re-Built")

The sun is now moving across the sky at one second per hour representation. Notice also that the colours of the sky change as the sun dips and rises and the shadows grow long and short accordingly. This is because the light direction was set accordingly in the Blueprints. These values can be changed in the timeline editor. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide96.PNG "Scene Testing")

This is the completed Blueprint for the day-night cycle, complete with the nodes, connections, and flow of logic that is being used in the scene. This Blueprint will be used in the group’s Fire Fighter game to provide a more realistic environment with the addition of a day-night cycle. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide97.PNG "Completed Blueprint")


<h2>Unreal Engine and Blueprints: Section 6</h2>

Blueprints for Player AI Explosion on Collision: In this example I am learning to create a Blueprint scenario in which an AI collides with a player, catches on fire, and damages the health of the player. Begin by duplicating the character in the scene. Go to the Blueprints folder > ThirdPersonCharacter, then right-click and select Duplicate. Rename the new asset that has been created to a meaningful name. I have labelled this asset TP_Duplicate. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide98.PNG "Setup Blueprint")

Double-click the TP_Duplicate asset to enter its Blueprints class. Delete the entire set of nodes and logic flows as these will all be re-built from scratch. Once that’s done, navigate to the Add Component button at the top left of the window, in the Components pane. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide99.PNG "Duplicate Character for Testing")

In the search bar, type in Pawn Sensing. The Pawn Sensing function allows the AI to interact or sense the main character in the game, and then perform various tasks including following the main character and exploding or catching on fire. Once that is done, click compile. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide100.PNG "pawn Sensing")

Select the Pawn Sensing component from the pane on the left, then right-click in the Blueprints window and create a node titled Add On See Pawn. A red event node is created. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide101.PNG "On See Pawn")

Drag out a connector from the white pin of the On See Pawn node, then type Cast To Third Person Character to create the corresponding node. This will allow the event to see the character and then perform a scripted action. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide102.PNG "Cast to Character")

Drag out a new connector from the Cast To Third Person Character node and create an AI Move To node. This node tells the AI where to move when the game is run. Then, connect the blue pin (As Third Person Character) from the Cast To Third Person Character node to the blue pin of the AI Move To node (Target Actor). Next, drag out a connector from the blue pin (pawn) of the Ai Move To node, then type in Self to create a Self node, which will link the AI’s movements back to itself. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide103.PNG "Cast to Character")

From the Object pin on the Cast To Character node, drag out a connector, then type Get Player Character to create a new function node titled Get Player Character. At this stage, if compile is clicked, the duplicate AI (which requires dragging onto the scene from the icon tray) is created and will follow the main character around the scene without colliding or causing any interaction. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide104.PNG "Cast to Character")

From the white pin titled On Success, in the AI Move To node, drag out a connector and type DestroyActor to create the corresponding function node. This relationship is to destroy the AI itself upon successful collision with the main character. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide105.PNG "AI Destruction")

From the white pin on the Destroy Actor node, drag out a connector and create a Spawn Emitter at Location node. Under the Emitter Template dropdown, choose P_Fire. This makes the AI catch fire when it collides with the main character. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide106.PNG "Spawn Fire")

In order to make the AI’s fire occur where the main character or player is, a new node is required. Drag out a connector from the yellow Location pin on the Spawn Emitter at Location node, and create a new node titled GetActorLocation. This function node controls where the fire will occur when the AI collides, i.e. wherever the player’s location is. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide107.PNG "Fire Emission Location")

In order for the main character to lose health on impact with the AI, a health variable needs to be created. Open up the Blueprints for the main character, i.e. ThirdPersonCharacter by double-clicking, then create a new variable. Rename this variable to something meaningful. I titled the variable MyHealth. Then navigate to the Details pane on the right, and from the Variable Type dropdown box, choose Integer. This is a number that can be incremented or decremented. Once this is done, save this ThirdPersonCharacter Blueprint, and return to the AI, i.e. TP_Duplicate Blueprint. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide108.PNG "Player Health Variable")

In the TP_Duplicate Blueprint, navigate back to the Cast To Third Person Character node, then drag a connector from the pin titled As Third Person Character and create a new node by typing in the name of variable, i.e. MyHealth. This is why it is important to use meaningful names that are easy to recall because these assets are stored within Blueprints for later references. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide109.PNG "Linked Health Vairable to AI Impact")

From the SET node containing the player health variable, connect the white pin to the corresponding white pin on the Spawn Emitter at Location node. Then drag out a connector from the MyHealth pin on the SET node and create a -integer node. This will decrease the player’s health upon collision with the AI. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide110.PNG "Decrease Health Integer")

Once again, navigate back to the Cast To Third Person Character node, then drag yet another new connector from the pin titled As Third Person Character and create a new node by typing in get My Health. This will create a new node that targets the current health of the player. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide111.PNG "Calculate Current Health and Decrement on AI Impact")

Connect the pin titled My Health on this new node to the top pin of the -integer node. In the bottom pin of the -integer node, type in 34 in the numbers value box. Note that this box is a percentage, so that every hit takes away a percentage of the player’s life. By setting it to 34, the player has three chances before all life is gone (i.e. when the total hits exceed 100%). When this is done, click compile. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide112.PNG "Three Lives Given to Player")

If for any reason the AI does not follow the main player, navigate to the left pane, click on Volumes > Nav Mesh Bounds Volume and drag this bounding box onto the scene. Scale up the box to as big as possible to cover the entire play area. I used 30 for the X, Y, and Z values. Once done, click play and begin running immediately. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide113.PNG "Volume Bound Mesh")

The AI now collides with the main player and sets the player on fire. Now that I have learned how to make objects move towards the main character and cause the main character to catch on fire and lose health, I will be integrating this Blueprint into our project as the logic for which the fire fighter will lose health if the fire coming towards the player is not put out in time or by using an adequate fire suppressant. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide114.PNG "Testing Blueprints")

This is the complete Blueprint for the AI script and behaviour governing its logic. The final step is to destroy the main character when health levels fall below zero. This is done in the ThirdPersonCharacter Blueprint, and not in the AI TP_Duplicate Blueprint. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide115.PNG "Final Blueprints")

In the ThirdPersonCharacter Blueprint, create a new event node called Event Tick. This node measures a value at each second of the game, in this case the player’s health. Create another node called Branch. The Branch node provides a Boolean measure (true or false). Drag out a connector from the Condition pin on the Branch node and type Integer < Integer to create the corresponding node. This node sets up a condition such that if the player’s health is less than 1 or 0, the Branch will perform a function. Drag out a connector from the True pin on the Branch node (since True means the condition satisfies the requirements) and create a new node function called DestroyActor. This logic is now complete. If the player’s health is less than 1 or 0, the player is destroyed. The Blueprint uses the Event Tick node to constantly measure if the player’s health is greater than 1 and if not, will pass off the function of killing the player via the Branch and DestroyActor nodes.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide116.PNG "Measuring Current Player Health")

<h2>Unreal Engine and Blueprints: Section 7</h2>

In several instances, a GitHub credential error might occur, which prevents pushing the changes made to the Blueprints out into the GitHub repo. This error is commonly associated with repos that have Git LFS (Git Large File Storage) installed. In this case, the error says 'Exit Status 1'. The image of the error screen is as follows: ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints-images-folder/GitHub-Credential-Error.PNG "GitHub Credential Error")

If an error such as the one documented above is encountered, proceed to do the following: Make sure Git is installed on the computer encountering the error. Open GitHub Desktop > Repository > Open in Command Prompt. In the Command Prompt type the following line of code: <pre><code>del /f .git\hooks\pre-push</code></pre> and ensure that all spaces are followed exactly as typed in the code. Hit 'Enter' or 'Return' then push the commits again. (This fix is for Windows but also works on Mac. For Mac computers, follow the exact procedure described, but use the Terminal app instead of the Command Prompt). The image of the fix screen is as follows: ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints-images-folder/GitHub-Credential-Fix.PNG "GitHub Credential Fix")

The FBX asset for the barbecue stove has been completed and imported into the Blueprints folder. The asset interacts with the player as a game object and can now be manipulated through Unreal Engine's Blueprint programme options. In this example I have overlaid the barbecue stove asset with an object on fire to preview the effect as it would appear during gameplay. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide117.PNG "BBQ Stove FBX")

The barbecue stove has been re-shaded using native Unreal Engine shaders to integrate the asset into the scene. A darker hue was applied to give it a pre-burnt effect, which aids player recognition and learning when encountering the object. This barbecue stove requires an H2O suppressant and will be lit up using the red colour fire. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide118.PNG "BBQ Stove Re-Shaded")

The FBX asset for the chair has been completed and imported into the Blueprints folder. Like the BBQ stove, the chair was imported as an FBX asset and is now a game object that can be interacted with the player. The chair has a few additional shaders added to its different components. Using Blueprints and the in-built materials of Unreal Engine, I was able to give the chair a wooden texture, which works appropriately since this is a fire hazard that requires the H2O suppressant. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide119.PNG "Chair FBX")

With the base material applied using Blueprints, I navigated to the Materials folder (by clicking on the preset material and choosing New Material Instance. I then took an existing wooden material and re-applied it to the chair to create the wooden frame and body. I also saved this material as a unique instance for the chair. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide120.PNG "Chair Material")

The final step was to integrate the chair into the scene and scale its size to fit with the rest of the game objects. As this chair will be a haunted item (i.e. will have its own laws of physics) it is important that the chair look and feel as natural as possible so that when the non-physical behaviour commences, the player's experience of the haunted fire tunnel will possibly be enhanced. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide121.PNG "Chair Integration")

In creating the smokey hissing sound for when an object's fire is extinguished, we created a Blueprint logic that blasts the sound initially, but then fades the sound out to create a more realistic suppressant effect. We were able to achieve this logic for all objects by applying a FadeOut function to the pre-built sounds offered within Unreal Engine. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide122.PNG "Smoke Fade Out Sound")


<h2>Unreal Engine and Blueprints: Section 8</h2>

To create a new level in Unreal Engine 4, click on File > New Level, then choose the default option. Unreal Engine 4 will create an empty scene. In this mode the entire scene and all its elements can be built from scratch using the tools and options provided in Unreal Engine. The basic setup even allows for no floor at all, a useful feature for games that require scaling or flight management scenarios. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide123.PNG "Tunnel Terrain")

Click on the Landscape icon (the image of a mountain) from the Modes panel on the top left to bring up the landscape editor. This editor enables resizing of the landscape along the X (length), Y (width), and Z (thickness) axes. It is very important to note that the Z location and the Z Scale must be the same so that the player is either on the terrain or above it, but never below it, otherwise the player will either fall through the ground, or remain stuck and unable to move before gameplay commences. In this example, I will be leaving the scale as 100 by 100. The Section Size (measured in Quads) is the number of checked squares. The more squares the higher the resolution. I will be setting this Section Size to 63 by 63 quads. Finally, I will be setting a material for the scene, in this case old brick. Once all the settings have been entered, click ‘Create’. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide124.PNG "Landscape Edits")

The flooring of the tunnel has been created in the old, underground brick style. Currently, the scene is open on all sides but this will be addressed at a later stage by adding walls and a ceiling around the playable area. While the material is adequate, the flooring looks far too new by virtue of its evenness. This can be fixed by using the Sculpt tool to add a variety of topographies and features to the terrain. Navigate to the Sculpt tool and explore the options presented. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide125.PNG "Brick Materials")

In this example I have used the hydro-erosion, erosion, smooth, and noise options to create an older-looking, uneven terrain. By adjusting the settings under each option (using the sliders and values in the Tool Settings panel) the terrain can be manipulated into the desired effect. Similar effects can also be applied to the walls and ceiling of the scene to create a systematically random worn-out look. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide126.PNG "Unevenness")

I have added a ramp to this scene to test the viability of creating deliberately uneven surfaces made by humans, juxtaposed with unevenness caused by natural wear and tear. Unreal Engine 4 provides ample options to create a variety of terrains and effects using the in-built tools. Combined with lighting and atmospheric fog, the appropriate scene of a haunted tunnel will be modelled and constructed almost entirely within Unreal Engine. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide127.PNG "Ramp")

In this example I am using the ramp to test the effects of the vanishing point by creating a narrowing perspective. The terrain is already starting to resemble a worn out tunnel. Further refinements will be carried out as the level is constructed, but this Blueprint will help the group to rapidly prototype and test playability within the environment of the game. A useful tip to begin gameplay at the point of edit, is to right-click and choose the ‘Play From Here’ option. This option begins gameplay at the point of view during edit, rather than at the fixed spawn point of the scene, which occurs when the Play button (top menu) is pressed. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide128.PNG "Playing From Immediate Area")

This is the first render of the tunnel environment scene, currently under testing for materials adequacy and basic geometry / topography. As the group imports more assets into the scene, the lighting and atmosphere will consequently be adjusted to drive the visuals towards our ultimate haunted tunnel environment. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide129.PNG "Initial GamePlay Environment Testing")

<h2>Unreal Engine and Blueprints: Section 9</h2>

Creating the Fire Cave: In this stage, I will be creating the environment from scratch for the Fire Fighter game that I am building and prototyping. I will start by creating the landscape and then proceed to build the character attributes and play assets. Start by creating an empty project, then scale the landscape along the x and y axes to increase the play area. Because this is going to be the entrance to a cave, I have lengthened the x axis to 8.0 and the y axis to 2.0. I have left the z axis as-is as the thickness of the landscape will be immaterial to the gameplay. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide130.PNG "Final Landscape Build Commenced")

To optimise the development, I have disabled Realtime by clicking on the dropdown arrow at the top left and deselecting the checkbox that says Realtime. This will increase the viewport render and take up fewer computing resources since building in Unreal Engine can be CPU-intensive.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide131.PNG "Disabled Realtime")

I have added a box asset to the scene to get a sense of the scale of the environment since the player needs to be proportionate to the environment in which it is operating. I dragged the box in from the Geometry panel and resized it using the scale tool to 0.1 along the x axis, 0.1 along the y axis and 0.4 along the z axis. The box now represents the width and height of the player. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide132.PNG "Box Asset Added")

Add the Unreal Engine 4 mannequin to the scene. If the mannequin is not in the content folder as an asset, download the mannequin for free from Unreal Engine 4’s marketplace, then follow the prompts to add the mannequin asset to the project, in this case my cave scene. Unreal Engine 4 will create a new folder in the Content Folder, with the title, UE4_Mannequin_Mobile. Double click to open this folder, then navigate to the Mesh folder and double-click that folder. Left-click and drag the mannequin onto the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide133.PNG "UE Mannequin Added")

Here I have rotated and resized the mannequin to match the proportions of the scene, using the initial block I created as a yardstick. With the mannequin in the scene and at the correct proportions, I can now start building out the landscape of the cave. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide134.PNG "Positioned UE Mannequin")

To add to the feeling of the scene, I have changed the sunlight colour to a more reddish-purple glow that is symptomatic of a distant fire. I have also played with the shadows to make them darker and more intense, which will add to the feeling of the game’s intensity. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide135.PNG "Sun Colour to Pink-Purple")

Add atmospheric fog to the scene by dragging the Atmospheric Fog asset from the Visual Effects panel onto the scene. Use the move tool to position the cloud icon (representing the atmospheric fog). Ensure that while the sunlight asset is selected, within the Light dropdown section (advanced options) the Atmospheric Sun Light checkbox is selected. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide136.PNG "Atmospheric Fog")

Use the Box asset to add two side walls and a far wall to block off three of the four openings to the scene. The area behind the character is the entrance to the landscape area and will therefore remain open. It is simpler to create one long wall, scale and position it perfectly, then duplicate it (Ctrl + W) and position it along the other edge of the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide137.PNG "Walls")

Add a player start point to the scene by clicking on the Basic panel and choosing the Player Start asset. Drag the asset to the scene and position it over the player. The player start asset will inform of whether the mannequin size and the player start mesh size are commensurate with each other. If they are not the player start asset will display a sign saying ‘Bad Size’. Resize the player start asset using the scale tool to make the mesh the same size as that of the mannequin. Once the sizes are in proportion, the ‘Bad Size’ sign will disappear. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide138.PNG "Start Asset")

To ensure that the light distribution is even across the scene, drag out a lightmass importance volume asset from the Volumes pane, and resize the lightmass importance volume box to cover the play area.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide139.PNG "Lightmass Importance Volume")

Using the materials palette in the StarterContent folder, give the walls and the flooring a watery material to provide a dynamic and hypnotic effect. The continuous motion provides an interesting visual and complements the element of water as the mainstay of the game’s strategy to put out the fires. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide140.PNG "Watery Material")

I have added a ceiling to the landscape and given all the walls a fluid, watery material that keeps moving randomly. The environment in its basic form is beginning to take shape. With the ceiling in place, the corridor has a spooky but futuristic appearance that invites a degree of exploration, which is the purpose of the game. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide141.PNG "Scene Ceiling")

To give the scene a more futuristic lighting effect I am creating a Tron-like glow material from scratch within Blueprints. This glow should provide the landscape not only with some visual interest but also add to the playability of the scene by providing implicit direction of where the player needs to focus attention. Start by creating a new material, giving it a name (I called mine Tron_Glow) then double-click the material icon to access its Blueprint. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide142.PNG "Tron-Like Effect")

To get the Tron-like effect, first create a Text Coordinate node. Then drag out a Mask node from the white pin of the Text Coordinate node and create a Mask node. In the Material Expression Component Mask pane (bottom left) click only G for the green channel. Duplicate this Mask node, drag out and connect another link from the Text Coordinate white pin, and this time click only R for the red channel. Drag out connectors from both masks and add Multiply nodes. In the expression box, change the multiply value from 1.0 to 0.5. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide143.PNG "Text Coordinates and Masks")

Add two Sine nodes, one for each Mask and connect them up with their respective white pins. The add a one-minus node, duplicate it, and again link up the one-minus nodes to the Sine nodes via the white pins. The effect of the black and white gradient lines are now more prominent. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide144.PNG "Sine and One-Minus Nodes")

Add two more Power (exponent) nodes and connect one to each of the one-minus nodes via the respective white pins. Then create a Scalar Component, give it a name (since it will be labelled as None by default). I called mine Scalar-Properties. In the Default Value input box for the Scalar-Properties node, type 30. Link up the Exp pins on both the Power nodes to the white pin on the Scalar Properties node. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide145.PNG "Power and Scalar Component One")

Add two more Subtract nodes and another Scalar Component node. For the Subtract nodes, put in 0.1 for the value. Next, create a new Scalar Property node, and give it any name. I gave mine Scalar-Properties-Two. Then link the A pins on the Subtract nodes to each of the power nodes, and link the B pins on the Subtract nodes to the single white pin on the new Scalar-Properties-Two node. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide146.PNG "Subtract and Scalar Component Two")

Add a linear interpolate node (defaults to a Lerp node). Then drag out a connector and create a Multiply node. Create another Multiply node and connect the two Multiply nodes together. Create a Vector Parameter node and rename it Colour. Choose a colour from the default value box. I chose a matching pinkish-purple. Create another Scalar Component node which will control the glow strength and name it. I called mine Scalar-Properties-Three. Connect the white pin on this node to the white pin on the newest Multiply node. Finally, connect the white pin from the newest Multiply node to the Emissive Colour pin on the Tron_Glow material node. The box in the left panel now has glowing pinkish-purple edges and is ready for use.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide147.PNG "Linear Interpolation and Third Scalar Node")

This is the result of the Tron Blueprint. The Scalar-Properties One, Two, and Three can be controlled using the sliders, which will affect the glow strength, intensity and size of the object to which it has been assigned. Even the colour can be changed.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide148.PNG "Final Result on Box I")

By playing with the values a variety of different effects can be achieved for the glow shape. Adjust each of the three sliders to achieve the desired effect. To get these corner-type effects, set the first Scalar Property to 5, the second to 1.3 and the third to 0.5. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide149.PNG "Final Result on Box II")

Here is the Tron glow effect added to the landscape walls. The glowing edges create a natural vanishing point towards the playable area, and add plenty of visual interest to the scene. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide150.PNG "Laser Outline Applied to Walls")

In this iteration, I have created a new material instance and applied it to the mannequin itself. The suit is now glowing and the outline looks much more dynamic and appealing than the default white material. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide151.PNG "Laser Outline Applied to Mannequin")

Here is the final iteration of the scene, ready for use in the final game play. The fiery red wall at the end of the vanishing point is the source of all the fire and will spawn all the objects that will come towards the player. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide152.PNG "Laser Outline Applied to Fire Spawn Area")

To keep the player within the bounds of the game, I have created a series of laser bars that prevent the player from exiting the playable area. The laser bars, like everything else in this landscape scene, are built entirely of the Tron custom material that I have created and that will power most of the environmental assets of this game. The material is built entirely of colour values and requires no textures. Therefore the load on the game is minimal while the effect is at full force. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide153.PNG "Final Environment Complete")

<h2>Unreal Engine and Blueprints: Section 10</h2>
In this Blueprint, I am creating a fire and water projectile system. The first step is to open the First Player HUD and correct the cross-hairs so that the projectiles are vectored in the precise direction of the shooter’s sights. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide154.PNG "Adding Water and Fire projectiles")

The cross-hairs have been correctly aligned along the X and Y axes for the shooter sights. Click ‘Compile’ and exit the First Person HUD blueprint. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide155.PNG "Cross-Hairs")

Next, open the First Person Character blueprint to align the character itself along the target cross-hairs and also delete any spheres from the shooter. This is because the spheres (default) will be replaced by fire and water projectiles. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide156.PNG "First-Person Shooter View")

Focus on the Spawn Projectile section of the blueprint, then click on the ‘Sphere’ component listing on the left panel, and delete this sphere from the FP Gun. This will get rid of the default yellow balls that Unreal Engine employs. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide157.PNG "Removed Default Sphere")

Then, delete the ‘GetWorldLocation’ node since the location is no longer a factor without the spheres. These spheres will be replaced by the fire / water projectile streams. Click ‘Compile’ but do not exit the blueprint as yet; the fire and water projectiles will be added next. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide158.PNG "Get World Location")

Create a new ‘Left Mouse Button’ node in the space below the Spawn blueprint node set. Then drag out a connection from the ‘Pressed’ pin and create a new node called ‘Branch’. The ‘Branch’ node will control the condition during fire. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide159.PNG "Assigned Left Mouse Button")

Drag out a connection from the red connection pin of the ‘Branch’ node and click ‘Promote to Variable’ to make the node into a variable. The ‘Branch’ node will check whether the gun is shooting fire or water. In the Variable Name field (right panel) enter a name for the variable, in this case isFire. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide160.PNG "Branch Variables")

Create two more ‘Add Custom Event’ nodes, and give each one a name. The first one is called ‘ProjectFire’ and the second one is called ‘ProjectWater’. As might be expected, each custom event will be connected up to the relevant projectile, i.e. fire or water. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide161.PNG "Custom Events")

Create a new function and call it ‘LineTrace’. Drag out a connector and create a node called ‘Sequence’. Drag out a connector from the ‘Then 0’ pin on the ‘Sequence’ node and create a new node called ‘LineTraceByChannel’. Next, pull in the ‘First Person Camera’ node from the panel on the left. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide162.PNG "Camera Line Tracer")

Drag out a connector from the ‘First Person Camera’ node and create a new node called ‘GetWorldLocation’. This will establish the world location for the shooter and projectile. Connect the ‘Return Value’ pin from the ‘GetWorldLocation’ to the ‘Start’ pin on the ‘LiveTraceByChannel’ node. Next, drag out a new connector and create a new node called ‘GetForwardVector’. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide163.PNG "Forward Vector")

From the ‘GetWorldLocation’ node, drag out a connector from the ‘Return Value’ pin and create a ‘x float’ node. Change the value in the box to 5000. Then drag out a new connection from the ‘Return Value’ pin on the ‘GetWorldLocation’ node and create a ‘+vector+vector float’ node. Connect the ‘x float’ yellow pin to the ‘+vector+vector float’ node. The node will change type. Then connect the new node type’s yellow pin to the ‘End’ pin on the ‘LiveTraceByChannel’ node.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide164.PNG "Live Trace Channel")

Drag out a new node called ‘Break Hit Result’. This node controls the end of the action. Create one more ‘x float’ node and one more ‘+vector+vector’ node. Connect up the ‘Location Pin’ on the ‘Break Hit Result’ node to the ‘+vector+vector’ pin, then drag out a connection from the outgoing yellow pin to create a new ‘LineTraceChannel’ node. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide165.PNG "Updated Live Trace Channel")

Connect the ‘x float’ node to the ‘+vector+vector’ node. Finally, create a new ‘Branch’ node and connect the ‘False’ pin from this node to a new ‘LineTraceByChannel’ node. Then drag a connector from the white pin of the ‘Branch’ node to the ‘Then 0’ pin of the ‘Sequence’ node created earlier. Click compile and save. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide166.PNG "Line Trace Completed")

The next stage is to work on the first person weapon blueprint, found under ‘FP Weapon’ in the ‘First Person’ folder. Click on Skeleton from the top right, then right click on Grip Bone from the left panel options and create a new socket. Click on Muzzle and move the socket into position. This will be the spawn point for the projectile. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide167.PNG "Adjusted Muzzle Socket")

Return to the ‘First Person Character’ blueprint, then create the ‘FP Gun’ node. Connect the pins to the ‘LineTraceByChannel’ nodes and click ‘Compile’ then save the blueprint. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide168.PNG "Updated First Person Gun")

In the Event Graph set up the logic for the fire and water by using the functions created in the previous steps. Then create a ‘flipflop’ node and connect it to a new ‘keyboard X’ node. Hitting x will switch between the fire and water projectiles. Click compile and save. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide169.PNG "Flip Flop Functionality")

This is the shooter with a water projectile.  ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide170.PNG "Water Projectile")

This is the shooter with a fiery projectile. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide171.PNG "Fiery Powder Projectile")

I have also created a stormy water environment for the game, which flows in rapidly from the outside and interacts with the fire to create steam. This is the blueprint for creating the stormy water texture for the floor of the environment. The blueprint instance allows for customisation of the speed and colour of the water as well as several parameters for fine-tuning. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide172.PNG "Stormy Water")

This is the demonstration of the flowing water storming across the environment, from behind the player, and hitting the far wall ahead, which is on fire. The resulting steam adds to the effect. In the sky above the force field lines can be seen, giving the player an added hemmed in feel, commensurate with the panic of being trapped in a room on fire. ![alt tag](https://github.com/arjunkhara/FireFighterGame/blob/master/blueprints/unreal-blueprints-images-folder/Slide173.PNG "Final Environment")

In this stage I am building a welcome / start screen for players to interact with before gameplay commences. This screen is built using Blueprints and the UI Widgets tool directly within Unreal Engine 4. The artwork was done on Photoshop and Illustrator, then imported into Unreal Engine 4. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints-images-folder/Slide174.JPG "Introduction Menu")

I have created an image placeholder and anchored it to the homescreen. In the step I will use the Brush option to select the pre-built image I have made for the splash screen. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints-images-folder/Slide175.JPG "Splash Screen Placeholder")

The background splash has been created and the image is within the placeholder. The next step will be to add in the button UI elements to begin the game / quit to main menu. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints-images-folder/Slide176.JPG "Background Image")

These are the blueprints for the title screen, which will be removed when the player clicks ‘Start’. If the player clicks ‘Quit’ the game defaults back to the main start point; in development mode this is the editor screen, but in Launch mode it will quit the program and return to the desktop. ![alt tag](https://github.com/arjunkhara/Unreal-Engine-Fire-Fighter-Game-Repo/blob/master/blueprints/unreal-blueprints-images-folder/Slide177.JPG "Blueprints Background Image")




___

# Final Game Report (Arjun Khara)
#### This report has also been published as a PDF: https://www.nano.training/Goldsmiths-Final-Game-Report-Programming-Modelling-Arjun-Khara-2018.pdf

<h4>Introduction</h4>
This report forms a formal part of, and frequently references, the documentation and learnings recorded in my GitHub repository. ‘Haunted Hose’ (developed under the pseudonym ‘FireFighter’) is a video game, built and programmed entirely by two team members, Arjun Khara and Daniel Nicholson, for the final winter term projects at Goldsmiths College, University of London, to fulfil the requirements for two college modules: Introduction to Programming, and Introduction to Modelling and Animation. The project is categorised as a serious game owing to  its additional characterising goals, beyond pure entertainment, of fire-safety education and awareness, specifically on suppressant types — water, carbon dioxide, and powder — used to combat various fires. The game was built on Unreal Engine 4 using a combination of Blueprints and direct C++ programming. Models and assets for the game were created using Maya and Blender, which were then imported into Unreal Engine as FBX objects and reconstructed for game use. Development commenced in mid-October 2017, and concluded in mid-January 2018 as a minimum viable product (MVP) to meet the assessment requirements for both the modules.

<h4>Conceptualisation</h4>
The idea of a fire-fighting game originated out of a shared interest between the two team members about the relative lack of interest in fire safety procedures and basic awareness of a threat that has consistently plagued communities and societies across time and geographies. Rudimentary gap analysis, conducted by the team, revealed a clear disconnect between the seriousness of the issue, and the nonchalant attitudes towards the problem. Fire safety is typically relegated as the concern of occupational and site experts, and not in the domain of everyday life. This outlook is common across societies throughout the world, and formed a point of discussion between the members, one of whom is from Asia and the other from the United Kingdom. The team decided to tackle this issue by creating a game that would entertain and educate. The game is therefore an interpretive, though not so much auteur-driven, practice of defining a hypothetical scene in which to act out present realities. The opponents as well, inanimate items (chairs, paint cans, electric SUVs), remain persuasively effectual in interacting within the familiar bounds of a typical first-person shooter.

<h4>Gameplay</h4>
The essence of ‘Haunted Hose’ is to extinguish various fires by choosing an appropriate suppressant. The game begins in a futuristic haunted passageway with a Tron-like decor, in which ordinary household items are unexpectedly set ablaze and hurtle towards the player, who must quickly toggle between three suppressants to put out the conflagration. The player experiences a first-person point-of-view: holding a snazzy hose from the future, and looking down the passageway to an inferno at the end. From this inferno emerges flaming chairs, statues, tomb stones, electric cars, and barbecue stoves. The player is required to adapt quickly to the oncoming object, gauge the type of fire from the colour of the flame, and choose the correct suppressant for the hose. There are three types of fire: regular; electric; gas. Likewise, the hose contains a suppressant for each: water; carbon dioxide; powder. When the appropriate suppressant is utilised, the fire, and the object, are  both extinguished and the player progresses. Using an incorrect suppressant on a fire grows the conflagration and the approaching object collides with the player causing damage to the player’s health. Three burning hits results in the player’s health being fully depleted and gameplay ends. In this respect, the game functions as an extradiegetic narrative, in which the player, and not an external narrator, forms the story and progression of the game within the fixed physical environment. As an MVP the game delivers on this mechanic; in future versions, the game contains a quiz on fire safety issues, which a player may quickly answer correctly to gain an extra life. The game is therefore entertaining at a surface level, but this is an exiguous stance that is embedded within particularised mechanics which drive the player to make decisions that mirror real life. The underpinning sphere of accuracy contains the game’s ethos of amusement and eduction, which characterises it as a serious game with distinct exigencies for both cognition and recognition.

<h4>Platform</h4>
Developed specifically for the PC platform, the player’s controls were setup accordingly. The player is fixed in space, only able to swing left or right, and up or down. Forward and backward mobility has been restricted to reinforce the fixedness of the player’s position, and increase intensity of play. Controls from swinging left and right, and up and down, come from mouse movements. Toggling between suppressants requires clicking between the A, S, and D keys. The keys were chosen because: (a) these are most associated with control keys for PC games; (b) these are the initials of the names of each of the team members, when the team had three members, i.e. Arjun Khara, Sarah Chalk, and Daniel Nicholson. Clicking the left mouse button expels the suppressant. The right mouse button toggles between the three suppressants as an alternative to the A, S, and D keys. Though useful for quick selection options, the caveat is that the player needs to remember the order of suppressants when cycling through each with the right mouse button, whereas the keyboard keys each have a dedicated suppressant assigned. The team focused on this additional mechanic to increase the pressure and challenge as gameplay intensifies and a player faces the added confusion of choice of controls, over and above the need to select the appropriate suppressant. The team wanted to drive the idea of actual panic through a fun and unforeseen dilemma.

<h4>Development</h4>
A combination of software tools were used to build and manage this project. The game itself was built using Unreal Engine 4 in a first-person mode. Blueprints were used to develop the majority of the logic for the game’s performance and play applications, with smaller degrees of pure C++ programming occasionally used. Modelling for assets was done in Maya and Blender, then imported as FBX assets into Unreal Engine 4 and reconstituted to work in the game. Shaders, materials and textures were used in Maya and Blender, to assess the overall look and feel. Additional texture qualities were added from Substance Painter. Development for the environment was built entirely in Unreal Engine 4, using material instances to save on resources and keep game speeds optimised. Beyond these core tools, the team utilised supporting software for project management and collaboration. GitHub was used for version control, to collaborate across all builds and changes, and for sharing and storing all assets. Documentation for this project was recorded on GitHub’s readme pages, along with all referenced images of blueprints and 3D-modelling screenshots. In the beginning of the project, the team expected to use a waterfall approach to managing and building out this project, but as the team size felt to two members, a LEAN approach was adopted to keep the project on time and in control. Initial versioning and delegation of responsibilities were controlled through Trello to establish a Kanban control system. Tasks and duties were filtered through Trello before being accepted by each member. YouTube was used to demonstrate a video of the game play-through. The table below shows the objects and commensurate type of suppressant used to extinguish each object’s blaze.

<h4>Genre</h4>
‘Haunted Hose’ is predominantly a serious game with aspects of entertainment as a first-person shooter. The game’s formal features assign it to the categories that are typically populated by titles such as ‘Doom’ in which the mechanics and rules are largely similar to ‘Haunted Hose’. However, the more serious characteristics of the game underpin a somewhat nebulous quality for exact categorisation. The team perceives the game as having applications in entertainment and enrichment, although neither can be considered an absolute genre in which fictional worlds make an appearance. The mechanics and rewards system are structured but casual so as to label the game as having a specific audience appeal. To gamers, ‘Haunted Hose’ posits a cross-hybrid category.

<h4>Contextualisation</h4>
The context in which this game operates relates only to the first level of gameplay (owing to the MVP stage). In the starting level, the player is introduced to the game’s surroundings and has to quickly insert himself/herself into play. The first-person shooter mode will be familiar to virtually all computer gamers, which provides basic orientation for commencing gameplay. From that point the oncoming flaming projectiles become the mainstay of the game’s focus and for the player to instinctively engage with. This stage is critical for analysis since the reception of the game’s initial environment determines how the secondary levels will be built. Play progresses as the projectile speed and vector intensify, ultimately causing the player to lose the game. This core of player failure is inherent to the effectiveness of the game’s serious objectives: fire safety is ongoing; no one ever fully masters its practice. The game is thus segmented along its initial level of impression — the environment remains but the projectiles vary in both intensity and type of opposition to the player.

<h4>Challenges</h4>
The biggest challenge of this project was the sheer lack of team members. We started with a small team of four members. Ambitions were therefore managed towards a development group of four — two programmers and two modellers, with overlap between the roles of each member. However, two members withdrew from the university during the project's development, leaving Arjun Khara and Daniel Nicholson to pick up, model, and program the entire project. As all other groups were by then already confirmed and working on their own projects, the group was forced to work with just two people. Arjun and Daniel continued development and assumed all of the additional responsibilities of programming, modelling, substance painting and texturing, project management, and GitHub setup and integration. Neither Arjun nor Daniel has prior experience in Unreal Engine 4, and very little in the way of modelling and animation (only that which had been taught in the modelling module so far). Both members therefore committed to learning all of the software and programmes together, at nights after class and on weekends at Goldsmiths College. The game progressed over several iterations as core knowledge of the software tools increased. Ambitions and actions were constantly reinforced through meetings, which were held and recorded twice a week between the two team members. Arjun and Daniel continued programming and modelling over the December holidays to compensate for the loss in manpower, and the result was finalised in early January 2018. During this stage, the idea for a Tron-like futuristic environment was adopted and the particle systems and models were reworked to fit with the theme. Collaboration was through GitHub LFS, where large files were shared and tracked over a strictly agreed schedule to prevent overwrites and breakages. In the final (presentation) week of the project, Daniel unfortunately fell ill; Arjun continued with the final debugging and wrap-ups, and presented the game as scheduled.

<h4>Important Learnings</h4>
The multiplicity of issues necessitated a reasonable degree of task delineation despite Arjun Khara initially taking over modelling, environment and art, in addition to programming, while Daniel Nicholson took over blueprint integration. However, given the restricted team size of two, both members eventually were required to oversee the other’s operations. While tedious in execution, the practice did have positive outcomes: both members were exposed to voluminous amounts of programming and modelling alike; small team size meant rapid pivoting to new ideas and environment concepts was successful; differences between concept and execution were wholly apparent. It is unlikely that either team member will be in a situation where only two members are tasked with completing a working game, but the experience has been a unique and therefore useful process on which to build further experiences. As it turned out, the final game was built on both the team members’ respective laptops simultaneously, with each creating their own blueprints and architecture for integration. The formal structure of the game-build processes were therefore inseparable from the narratives of its individual elements.

<h4>Collaboration</h4>
The project was managed through GitHub repositories; a primary and a backup repository were established to store and track all development and changes. Given the size of the group — two members — there was no room for any major setback and the team decided to backup all major assets to a second GitHub repository, with LFS enabled for quickly uploading large files. While building a project of this scale taxed the resources of only two members, discussions, communication, and agreements were swift. GitHub Desktop was used as the go-between software to mange the growing repository and a filing system with clear nomenclatures was also established. Blueprint files were uploaded into designated folders, and every blueprint was photographed and posted as an image within the documentation files of the repository, together with clear explanations on the build process. Towards the end of the project cycle, a backup repository was established to hold the most important files in the event the main repository failed or disrupted commit permissions. This practice formed the core reference system for the team in which to manage each stage of the game’s wider scope and general complexities.

<h4>Conclusion</h4>
The end of the first term and its games project has produced a variety of insights and dilemmas into the discipline of producing a video game. It is interesting to note the synchronicity between modelling and reality – one requires perception, and the other, vision. This raises the possibilities of modelling not just for gaming applications but also as a socially-driven engine for virtual reality, narratives of art history, sociology and the implementation of the real versus realistic dichotomy in the entertainment business as a whole. In fact this is already difficult to define where a natural environment ends and a computational system begins. Modelling is one thing, but modelling specifically for a game requires two-fold thinking, in which the considerations lie not only in the object’s form and structure, but also with its function and performance as a game asset. The utility of animations (movement, scaling, burning, appearing and disappearing) requires an approach that sets one eye on the task and the other on the potential to meet future tasks. The workflow in this case includes thinking at two ends of the spectrum to allow for minimal disruption when transferring these assets from one medium to another. This is a new experience for the team, one which will provide ample insight and training to meet the rigours of working in the computer games industry.


<h4>Bibliography & Learning Sources:</h4>

• Beginning C++ Through Game Programming, Dawson, M (2015), United States of America: Cengage Learning

• Beyond the Internet and Web, in Society & The Internet, Wilks, Y., eds. Graham, M. and Dutton, W.H., (2014), Oxford: Oxford University Press

• Dean Ashford, on YouTube, accessible at: https://www.youtube.com/watch?v=aE0EbWdnjTI

• Introduction to Game Analysis, Fernandez-Vara, C (2015) New York: Routledge

• Jimmy Vegas, on YouTube, accessible at: https://www.youtube.com/watch?v=2sp3g5pSQEk

• Joseph Delgadillo, on YouTube, accessible at: https://www.youtube.com/watch?v=imLfBx8E4Wk

• Pub Games, on YouTube, accessible at: https://www.youtube.com/watch?v=6-ZwY4RDaPQ

• PyroDev, on YouTube, accessible at: https://www.youtube.com/watch?v=a3QZflKDi3w

• The Meaning of Video Games: Gaming and Textual Strategies, Jones, S. E., (2008) New York: Routledge 

• Tesla Dev, on YouTube, accessible at: https://www.youtube.com/watch?v=1aSdzw5zPtg

• Unreal Engine, on YouTube, accessible at: https://www.youtube.com/watch?v=pdjFm7YA8vI&t=97s

• Unreal Engine 4 for Design Visualization, Shannon, T (2018), United States of America: Addison-Wesley

• Virtus Learning Lab, on YouTube, accessible at; https://www.youtube.com/watch?v=w_j8BMg27u8
___


___

# Final Game Report (Arjun Khara)
#### This report has also been published as a PDF: https://www.nano.training/Goldsmiths-Final-Game-Report-Programming-Modelling-Arjun-Khara-2018.pdf

<h4>Introduction</h4>
This report forms a formal part of, and frequently references, the documentation and learnings recorded in my GitHub repository. ‘Haunted Hose’ (developed under the pseudonym ‘FireFighter’) is a video game, built and programmed entirely by two team members, Arjun Khara and Daniel Nicholson, for the final winter term projects at Goldsmiths College, University of London, to fulfil the requirements for two college modules: Introduction to Programming, and Introduction to Modelling and Animation. The project is categorised as a serious game owing to  its additional characterising goals, beyond pure entertainment, of fire-safety education and awareness, specifically on suppressant types — water, carbon dioxide, and powder — used to combat various fires. The game was built on Unreal Engine 4 using a combination of Blueprints and direct C++ programming. Models and assets for the game were created using Maya and Blender, which were then imported into Unreal Engine as FBX objects and reconstructed for game use. Development commenced in mid-October 2017, and concluded in mid-January 2018 as a minimum viable product (MVP) to meet the assessment requirements for both the modules.

<h4>Conceptualisation</h4>
The idea of a fire-fighting game originated out of a shared interest between the two team members about the relative lack of interest in fire safety procedures and basic awareness of a threat that has consistently plagued communities and societies across time and geographies. Rudimentary gap analysis, conducted by the team, revealed a clear disconnect between the seriousness of the issue, and the nonchalant attitudes towards the problem. Fire safety is typically relegated as the concern of occupational and site experts, and not in the domain of everyday life. This outlook is common across societies throughout the world, and formed a point of discussion between the members, one of whom is from Asia and the other from the United Kingdom. The team decided to tackle this issue by creating a game that would entertain and educate. The game is therefore an interpretive, though not so much auteur-driven, practice of defining a hypothetical scene in which to act out present realities. The opponents as well, inanimate items (chairs, paint cans, electric SUVs), remain persuasively effectual in interacting within the familiar bounds of a typical first-person shooter.

<h4>Gameplay</h4>
The essence of ‘Haunted Hose’ is to extinguish various fires by choosing an appropriate suppressant. The game begins in a futuristic haunted passageway with a Tron-like decor, in which ordinary household items are unexpectedly set ablaze and hurtle towards the player, who must quickly toggle between three suppressants to put out the conflagration. The player experiences a first-person point-of-view: holding a snazzy hose from the future, and looking down the passageway to an inferno at the end. From this inferno emerges flaming chairs, statues, tomb stones, electric cars, and barbecue stoves. The player is required to adapt quickly to the oncoming object, gauge the type of fire from the colour of the flame, and choose the correct suppressant for the hose. There are three types of fire: regular; electric; gas. Likewise, the hose contains a suppressant for each: water; carbon dioxide; powder. When the appropriate suppressant is utilised, the fire, and the object, are  both extinguished and the player progresses. Using an incorrect suppressant on a fire grows the conflagration and the approaching object collides with the player causing damage to the player’s health. Three burning hits results in the player’s health being fully depleted and gameplay ends. In this respect, the game functions as an extradiegetic narrative, in which the player, and not an external narrator, forms the story and progression of the game within the fixed physical environment. As an MVP the game delivers on this mechanic; in future versions, the game contains a quiz on fire safety issues, which a player may quickly answer correctly to gain an extra life. The game is therefore entertaining at a surface level, but this is an exiguous stance that is embedded within particularised mechanics which drive the player to make decisions that mirror real life. The underpinning sphere of accuracy contains the game’s ethos of amusement and eduction, which characterises it as a serious game with distinct exigencies for both cognition and recognition.

<h4>Platform</h4>
Developed specifically for the PC platform, the player’s controls were setup accordingly. The player is fixed in space, only able to swing left or right, and up or down. Forward and backward mobility has been restricted to reinforce the fixedness of the player’s position, and increase intensity of play. Controls from swinging left and right, and up and down, come from mouse movements. Toggling between suppressants requires clicking between the A, S, and D keys. The keys were chosen because: (a) these are most associated with control keys for PC games; (b) these are the initials of the names of each of the team members, when the team had three members, i.e. Arjun Khara, Sarah Chalk, and Daniel Nicholson. Clicking the left mouse button expels the suppressant. The right mouse button toggles between the three suppressants as an alternative to the A, S, and D keys. Though useful for quick selection options, the caveat is that the player needs to remember the order of suppressants when cycling through each with the right mouse button, whereas the keyboard keys each have a dedicated suppressant assigned. The team focused on this additional mechanic to increase the pressure and challenge as gameplay intensifies and a player faces the added confusion of choice of controls, over and above the need to select the appropriate suppressant. The team wanted to drive the idea of actual panic through a fun and unforeseen dilemma.

<h4>Development</h4>
A combination of software tools were used to build and manage this project. The game itself was built using Unreal Engine 4 in a first-person mode. Blueprints were used to develop the majority of the logic for the game’s performance and play applications, with smaller degrees of pure C++ programming occasionally used. Modelling for assets was done in Maya and Blender, then imported as FBX assets into Unreal Engine 4 and reconstituted to work in the game. Shaders, materials and textures were used in Maya and Blender, to assess the overall look and feel. Additional texture qualities were added from Substance Painter. Development for the environment was built entirely in Unreal Engine 4, using material instances to save on resources and keep game speeds optimised. Beyond these core tools, the team utilised supporting software for project management and collaboration. GitHub was used for version control, to collaborate across all builds and changes, and for sharing and storing all assets. Documentation for this project was recorded on GitHub’s readme pages, along with all referenced images of blueprints and 3D-modelling screenshots. In the beginning of the project, the team expected to use a waterfall approach to managing and building out this project, but as the team size felt to two members, a LEAN approach was adopted to keep the project on time and in control. Initial versioning and delegation of responsibilities were controlled through Trello to establish a Kanban control system. Tasks and duties were filtered through Trello before being accepted by each member. YouTube was used to demonstrate a video of the game play-through. The table below shows the objects and commensurate type of suppressant used to extinguish each object’s blaze.

<h4>Genre</h4>
‘Haunted Hose’ is predominantly a serious game with aspects of entertainment as a first-person shooter. The game’s formal features assign it to the categories that are typically populated by titles such as ‘Doom’ in which the mechanics and rules are largely similar to ‘Haunted Hose’. However, the more serious characteristics of the game underpin a somewhat nebulous quality for exact categorisation. The team perceives the game as having applications in entertainment and enrichment, although neither can be considered an absolute genre in which fictional worlds make an appearance. The mechanics and rewards system are structured but casual so as to label the game as having a specific audience appeal. To gamers, ‘Haunted Hose’ posits a cross-hybrid category.

<h4>Contextualisation</h4>
The context in which this game operates relates only to the first level of gameplay (owing to the MVP stage). In the starting level, the player is introduced to the game’s surroundings and has to quickly insert himself/herself into play. The first-person shooter mode will be familiar to virtually all computer gamers, which provides basic orientation for commencing gameplay. From that point the oncoming flaming projectiles become the mainstay of the game’s focus and for the player to instinctively engage with. This stage is critical for analysis since the reception of the game’s initial environment determines how the secondary levels will be built. Play progresses as the projectile speed and vector intensify, ultimately causing the player to lose the game. This core of player failure is inherent to the effectiveness of the game’s serious objectives: fire safety is ongoing; no one ever fully masters its practice. The game is thus segmented along its initial level of impression — the environment remains but the projectiles vary in both intensity and type of opposition to the player.

<h4>Challenges</h4>
The biggest challenge of this project was the sheer lack of team members. We started with a small team of four members. Ambitions were therefore managed towards a development group of four — two programmers and two modellers, with overlap between the roles of each member. However, two members withdrew from the university during the project's development, leaving Arjun Khara and Daniel Nicholson to pick up, model, and program the entire project. As all other groups were by then already confirmed and working on their own projects, the group was forced to work with just two people. Arjun and Daniel continued development and assumed all of the additional responsibilities of programming, modelling, substance painting and texturing, project management, and GitHub setup and integration. Neither Arjun nor Daniel has prior experience in Unreal Engine 4, and very little in the way of modelling and animation (only that which had been taught in the modelling module so far). Both members therefore committed to learning all of the software and programmes together, at nights after class and on weekends at Goldsmiths College. The game progressed over several iterations as core knowledge of the software tools increased. Ambitions and actions were constantly reinforced through meetings, which were held and recorded twice a week between the two team members. Arjun and Daniel continued programming and modelling over the December holidays to compensate for the loss in manpower, and the result was finalised in early January 2018. During this stage, the idea for a Tron-like futuristic environment was adopted and the particle systems and models were reworked to fit with the theme. Collaboration was through GitHub LFS, where large files were shared and tracked over a strictly agreed schedule to prevent overwrites and breakages. In the final (presentation) week of the project, Daniel unfortunately fell ill; Arjun continued with the final debugging and wrap-ups, and presented the game as scheduled.

<h4>Important Learnings</h4>
The multiplicity of issues necessitated a reasonable degree of task delineation despite Arjun Khara initially taking over modelling, environment and art, in addition to programming, while Daniel Nicholson took over blueprint integration. However, given the restricted team size of two, both members eventually were required to oversee the other’s operations. While tedious in execution, the practice did have positive outcomes: both members were exposed to voluminous amounts of programming and modelling alike; small team size meant rapid pivoting to new ideas and environment concepts was successful; differences between concept and execution were wholly apparent. It is unlikely that either team member will be in a situation where only two members are tasked with completing a working game, but the experience has been a unique and therefore useful process on which to build further experiences. As it turned out, the final game was built on both the team members’ respective laptops simultaneously, with each creating their own blueprints and architecture for integration. The formal structure of the game-build processes were therefore inseparable from the narratives of its individual elements.

<h4>Collaboration</h4>
The project was managed through GitHub repositories; a primary and a backup repository were established to store and track all development and changes. Given the size of the group — two members — there was no room for any major setback and the team decided to backup all major assets to a second GitHub repository, with LFS enabled for quickly uploading large files. While building a project of this scale taxed the resources of only two members, discussions, communication, and agreements were swift. GitHub Desktop was used as the go-between software to mange the growing repository and a filing system with clear nomenclatures was also established. Blueprint files were uploaded into designated folders, and every blueprint was photographed and posted as an image within the documentation files of the repository, together with clear explanations on the build process. Towards the end of the project cycle, a backup repository was established to hold the most important files in the event the main repository failed or disrupted commit permissions. This practice formed the core reference system for the team in which to manage each stage of the game’s wider scope and general complexities.

<h4>Conclusion</h4>
The end of the first term and its games project has produced a variety of insights and dilemmas into the discipline of producing a video game. It is interesting to note the synchronicity between modelling and reality – one requires perception, and the other, vision. This raises the possibilities of modelling not just for gaming applications but also as a socially-driven engine for virtual reality, narratives of art history, sociology and the implementation of the real versus realistic dichotomy in the entertainment business as a whole. In fact this is already difficult to define where a natural environment ends and a computational system begins. Modelling is one thing, but modelling specifically for a game requires two-fold thinking, in which the considerations lie not only in the object’s form and structure, but also with its function and performance as a game asset. The utility of animations (movement, scaling, burning, appearing and disappearing) requires an approach that sets one eye on the task and the other on the potential to meet future tasks. The workflow in this case includes thinking at two ends of the spectrum to allow for minimal disruption when transferring these assets from one medium to another. This is a new experience for the team, one which will provide ample insight and training to meet the rigours of working in the computer games industry.


<h4>Bibliography & Learning Sources:</h4>

• Beginning C++ Through Game Programming, Dawson, M (2015), United States of America: Cengage Learning

• Beyond the Internet and Web, in Society & The Internet, Wilks, Y., eds. Graham, M. and Dutton, W.H., (2014), Oxford: Oxford University Press

• Dean Ashford, on YouTube, accessible at: https://www.youtube.com/watch?v=aE0EbWdnjTI

• Introduction to Game Analysis, Fernandez-Vara, C (2015) New York: Routledge

• Jimmy Vegas, on YouTube, accessible at: https://www.youtube.com/watch?v=2sp3g5pSQEk

• Joseph Delgadillo, on YouTube, accessible at: https://www.youtube.com/watch?v=imLfBx8E4Wk

• Pub Games, on YouTube, accessible at: https://www.youtube.com/watch?v=6-ZwY4RDaPQ

• PyroDev, on YouTube, accessible at: https://www.youtube.com/watch?v=a3QZflKDi3w

• The Meaning of Video Games: Gaming and Textual Strategies, Jones, S. E., (2008) New York: Routledge 

• Tesla Dev, on YouTube, accessible at: https://www.youtube.com/watch?v=1aSdzw5zPtg

• Unreal Engine, on YouTube, accessible at: https://www.youtube.com/watch?v=pdjFm7YA8vI&t=97s

• Unreal Engine 4 for Design Visualization, Shannon, T (2018), United States of America: Addison-Wesley

• Virtus Learning Lab, on YouTube, accessible at; https://www.youtube.com/watch?v=w_j8BMg27u8
___

